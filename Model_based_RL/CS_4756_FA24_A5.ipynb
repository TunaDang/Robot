{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xso5Q-Lbynic"
   },
   "source": [
    "# Assignment 5: Model Based Reinforcement Learning\n",
    "\n",
    "### Due Date: \n",
    "Nov 26 at 11:59 PM \n",
    "\n",
    "### Writeup: \n",
    "https://docs.google.com/document/d/1PxXUYKqWdS1a9yF-o1UlY23QAlpu1qTrdoUfJfm6jlk/edit?usp=sharing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wDGlWqE5lGsU"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "\n",
    "Welcome to Assignment 5 of CS 4756/5756. In this assignment, you will explore the effects of model based reinforcement learning, while getting familiar with Stable Baselines, a popularly used reinforcement learning library. \n",
    "\n",
    "You will use the MountainCar-v0 environment for this assignment. Refer to the Gym website for more details about the [MountainCar environment](https://gymnasium.farama.org/environments/classic_control/mountain_car/).\n",
    "\n",
    "\n",
    "**Structure of Assignment:** \n",
    "This assignment is built up by the following components: \n",
    "- Setting Up: dependency installing and initializations \n",
    "- Helper Functions: A set of provided helper functions for you to evaluate and visualize policies. \n",
    "- Part 1: Introduction to StableBaselines3 package. You will implement some helper classes and write some scripts to train a PPO agent with StableBaselines3. \n",
    "- Part 2: Collect data on the MountainCar environment transition and train a world model \n",
    "\n",
    "*Note: Bulk of implementation is in Part 1 and 2, building your foundation of helper functions and classes to use in Part 3.*\n",
    "\n",
    "- Part 3: Train a learner PPO policy on the environment modeled in part 1 as world environment. \n",
    "- [GRAD] Part 4: Collect new data with learner policy and aggregate with expert collected data, repeat part 2 world model training and part 3 agent training. \n",
    "\n",
    "\n",
    "Please read through the following paragraphs carefully. \n",
    "\n",
    "\n",
    "**Getting Started:** You are free to complete this assignment on **either  [Google Colab](https://colab.research.google.com/) or your local machine**. Note that there will be a small amount of extra setup if you choose to complete the assignment on your local machine (see **Setup** section below).\n",
    "\n",
    "**Evaluation:**\n",
    "Your code will be tested for correctness and, for certain assignments, speed. For this particular assignment, performance results will not be harshly graded (although we provide approximate expected reward numbers, you are not expected to replicate them exactly). Please remember that all assignments should be completed individually.\n",
    "\n",
    "**Academic Integrity:** We will be checking your code against other submissions in the class for logical redundancy. If you copy someone else’s code and submit it with minor changes, we will know. These cheat detectors are quite hard to fool, so please don’t try. We trust you all to submit your own work only; please don’t let us down. If you do, we will pursue the strongest consequences available to us.\n",
    "\n",
    "**Getting Help:** The [Resources](https://www.cs.cornell.edu/courses/cs4756/2024sp/#resources) section on the course website is your friend! If you ever feel stuck in these projects, please feel free to avail yourself to office hours and Edstem! If you are unable to make any of the office hours listed, please let TAs know and we will be happy to assist. If you need a refresher for PyTorch, please see this [60 minute blitz](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html)! For Numpy, please see the quickstart [here](https://numpy.org/doc/stable/user/quickstart.html) and full API [here](https://numpy.org/doc/stable/reference/).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up\n",
    "As mentioned above, you are free to use Google Colab or your local machine for this assignment. Regardless of your choice, **you will need to run the cell below**. If you are using your local machine, though, you will first need to set up a conda environment that contains the packages found in requirements.txt.\n",
    "\n",
    "\n",
    "### Setting Up Conda Environment (Local Machine Only)\n",
    "\n",
    "In order to complete the assignment locally, you will need to install the required libraries. To do this, we will use the package manager [Conda](https://conda.io/projects/conda/en/latest/user-guide/getting-started.html).\n",
    "\n",
    "* First, create a Conda environment in the terminal with the correct version of python by running: `conda create --name cs4756_a5 python=3.10`\n",
    "* Next, activate the environment by running: `conda activate cs4756_a5`\n",
    "* Lastly, install the required libraries by runnning: `pip install -r requirements.txt`\n",
    "\n",
    "When you run the notebook, make sure to set the Python interpreter and kernel to be the version of python from the `cs4756_a5` environment. If you are using VSCode, you may need to restart after creating the environment in order for `cs4756_a5` to be a visible option that you can select for your kernel.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xHOfoL9J87BJ",
    "outputId": "1043e089-81a9-47dc-ca28-89ac1a17b53c"
   },
   "outputs": [],
   "source": [
    "# Set Up:\n",
    "import sys\n",
    "USING_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if USING_COLAB:\n",
    "    !apt-get install -y xvfb python-opengl ffmpeg > /dev/null 2>&1\n",
    "    !pip install -U renderlab\n",
    "    !pip install -U colabgymrender\n",
    "    !pip install -U moviepy==0.2.3.5\n",
    "    !pip install imageio==2.4.1\n",
    "    !pip install --upgrade AutoROM\n",
    "    !AutoROM --accept-license\n",
    "    !pip install gymnasium\n",
    "    !pip install gym[classic_control] > /dev/null 2>&1\n",
    "    !pip install stable_baselines3\n",
    "\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "seed = 24\n",
    "data_seed = 700\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rpTyu7Ap8_jA"
   },
   "source": [
    "## [PROVIDED] Helper Functions\n",
    "\n",
    "### Reseed \n",
    "\n",
    "We provide the reseeding function that will update the seed to a given customary seed passed in as parameter. This helps reproducibility of the code and hopes to eliminate confusion on achieved number results for the rest of this assignment. \n",
    "\n",
    "An optional parameter of `env` is passed in, such that when one is provided, the function will also set the seed of the random number generator of that particular gym environment.\n",
    "\n",
    "**Note**: All calls to this function will be given available to you for the rest of the assignment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the seed to ensure reproducability\n",
    "def reseed(seed, env=None):\n",
    "    '''\n",
    "        Sets the seed for reproducibility \n",
    "\n",
    "        When @param env is provided, also sets the \n",
    "        random number generataor of the gym environment \n",
    "        to this particular seed\n",
    "    '''\n",
    "    torch.manual_seed(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    if env is not None: \n",
    "        env.unwrapped._np_random = gym.utils.seeding.np_random(seed)[0]\n",
    "\n",
    "reseed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize\n",
    "\n",
    "Below, we provide the helper function `visualize` for your use. This function will create a visualization of your specified environment by running an episode with the provided algorithm. If you are using Colab, calling this function will render the visualization within the notebook. If you are using your local machine, this function will instead save a video of the visualization to your current directory (rendering videos in Jupyter Notebooks is not widely supported outside of Colab). \n",
    "\n",
    "**Note** that in this code, a choice is provided on whether to vectorize the environment. The difference across vectorized and not vectorized gymnasium environments will be explained in the StableBaselines Introduction section. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3aQv91DL9F-_"
   },
   "outputs": [],
   "source": [
    "def visualize(env_name='MountainCar-v0', algorithm=None, video_name=\"test\", env_args={}):\n",
    "    \"\"\"Visualize a policy network for a given algorithm on a single episode\n",
    "\n",
    "        Args:\n",
    "            env_name: Name of the gym environment to roll out `algorithm` in, it will be instantiated using gym.make or make_vec_env\n",
    "            algorithm (PPOActor): Actor whose policy network will be rolled out for the episode. If\n",
    "            no algorithm is passed in, a random policy will be visualized.\n",
    "            video_name (str): Name for the mp4 file of the episode that will be saved (omit .mp4). Only used\n",
    "            when running on local machine.\n",
    "    \"\"\"\n",
    "\n",
    "    def get_action(obs):\n",
    "        if not algorithm:\n",
    "            return env.action_space.sample()\n",
    "        else:\n",
    "            return algorithm.select_action(obs)\n",
    "\n",
    "    if USING_COLAB:\n",
    "        from renderlab import RenderFrame\n",
    "\n",
    "        directory = './video'\n",
    "        env_args['render_mode'] = 'rgb_array'\n",
    "        env = gym.make(env_name, **env_args)\n",
    "        env = RenderFrame(env, directory)\n",
    "        obs, info = env.reset()\n",
    "\n",
    "        for i in range(200):\n",
    "            action = get_action(obs)\n",
    "            obs, reward, done, truncate, info = env.step(action)\n",
    "\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "        env.play()\n",
    "    else:\n",
    "        import cv2\n",
    "\n",
    "        video = cv2.VideoWriter(f\"{video_name}.mp4\", cv2.VideoWriter_fourcc(*'mp4v'), 24, (600,400))\n",
    "\n",
    "        env_args['render_mode'] = 'rgb_array'\n",
    "        env = gym.make(env_name, **env_args)\n",
    "        obs, info = env.reset()\n",
    "\n",
    "        for i in range(500):\n",
    "            action = get_action(obs)\n",
    "            res = env.step(action)\n",
    "            obs, reward, done, truncate, info = res\n",
    "\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "            im = env.render()\n",
    "            im = im[:,:,::-1]\n",
    "\n",
    "            video.write(im)\n",
    "\n",
    "        video.release()\n",
    "        env.close()\n",
    "        print(f\"Video saved as {video_name}.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Policy Evaluation function\n",
    "\n",
    "The `evaluate_policy` function takes an agent actor, an environment whose output observations can be directly applied to the actor, and evaluates the policy by doing the following: \n",
    "\n",
    "- Rollout actor for a default of 100 trajectories, and record the total reward\n",
    "- Return the average trajectory rewards over these episodes. \n",
    "\n",
    "**Note**: since the actor we will be defining in this assignment exclusively uses a StableBaselines3 PPO agent, then the environment provided must be an instance of `VecEnv`, more information introduced in Part 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_policy(actor, environment, num_episodes=100, progress=True): \n",
    "    '''\n",
    "        Returns the mean trajectory reward of rolling out `actor` on `environment \n",
    "\n",
    "        Parameters \n",
    "        - actor: PPOActor instance, defined in Part 1 \n",
    "        - environment: classstable_baselines3.common.vec_env.VecEnv instance \n",
    "        - num_episodes: total number of trajectories to collect and average over\n",
    "    '''\n",
    "    total_rew = 0 \n",
    "\n",
    "    iterate = (trange(num_episodes) if progress else range(num_episodes))\n",
    "    for _ in iterate: \n",
    "        obs = environment.reset() \n",
    "        done = False\n",
    "\n",
    "        while not done: \n",
    "            action = actor.select_action(obs)\n",
    "            \n",
    "            next_obs, reward, done, info = environment.step(action) \n",
    "            total_rew += reward\n",
    "            \n",
    "            obs = next_obs \n",
    "    \n",
    "    return (total_rew / num_episodes).item() \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cUgJQoJ69QKS"
   },
   "source": [
    "## Introduction to the Mountain Car Environment\n",
    "\n",
    "MountainCar-v0 is a classic control problem in the field of reinforcement learning. The task is to drive the cart up the hill and to the goal on the right. The environment consists of a cart that can move along a track that changes in elevation, starting a various possible positions on this track. The goal is to reach the top of hte hill. \n",
    "\n",
    "The observation space consists of two variables: position of the car along the x-axis, and the velocity of the car. The action space includes three discrete actions: accelerate the cart to the left, do not accelerate, and accelerate the cart to the right. An episode ends when the cart reaches the top or when it has taken over 200 steps.\n",
    "\n",
    "**Run the cell below to visualize the MountainCar-v0 environment with a random policy:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 612
    },
    "id": "U75gc8b-9qD0",
    "outputId": "2d7c5876-3178-4b3c-b14c-b112b60b5c44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video saved as test.mp4\n"
     ]
    }
   ],
   "source": [
    "visualize(env_name='MountainCar-v0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QvDW2CKcyssI"
   },
   "source": [
    "## Part 1: Train an expert using StableBaselines3 \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nh6-BcrDk5Kt"
   },
   "source": [
    "### Overview: Introduction to Stable Baselines 3\n",
    "\n",
    "**Please Read Carefully**: Contains information necessary for following implementations. \n",
    "\n",
    "StableBaselines3 is popular off-the-shelf set of reliable implementations of reinforcement learning algorithms in PyTorch. \n",
    "\n",
    "In this assignment, we will be using its PPO (Proximal Policy Gradient) implementation as our agent. \n",
    "\n",
    "Each of the algorithm implementation is a subclass of the `stable_baselines3.common.base_class.BaseAlgorithm` class, which provides us with the following functions: \n",
    "\n",
    "- `learn(total_timesteps, callback=None, log_interval=100, tb_log_name='run', reset_num_timesteps=True, progress_bar=False)`: This is the training loop of any of the RL algorithm implementations. Training is done by calling this function with an appropriate amount of `total_timesteps` \n",
    "- `predict(observation)`: Returns a tuple `(predicted_action, next_hidden_state)` based on input `observation`. If we are not using an RNN, the next hidden state can be neglected. \n",
    "- `save(path)`: Saves the current policy parameters into a `.zip` file with given `path`. Note that the `path` does not have the `.zip` postfix. \n",
    "- `load(path, env=None)`: Loads a saved a `.zip` checkpoint into this RL implementation model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qF7g5LGEn5iH"
   },
   "source": [
    "### [PROVIDED] Hyperparameters\n",
    "\n",
    "There are a set of hyperparameters that can be tuned toward a better performance, for the sake of simplicity, we will provide the hyperparameters for the StableBaselines3 PPO implementation. The main ones we specify include the following: \n",
    "* `n_steps`: the number of steps to run with the environment for each update to the policy network\n",
    "* `net_arch`: The network architecture of the policy network and the critic network: \n",
    "  * `pi`: a list that specifies the hidden dimensions of the policy network. The input and output dimension are determined by the environment associated with this policy \n",
    "  * `vf`: a list that specifies the hidden dimensions of the critic network. \n",
    "  * `activation_fn`: Nonlinearity to be applied between each of the MLP layers \n",
    "\n",
    "For a more comprehensive list and description of each of these hyperparameters, visit the official [documentation page](https://stable-baselines3.readthedocs.io/en/master/modules/ppo.html#parameters) for more information. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "jwMlQmYQmu2e"
   },
   "outputs": [],
   "source": [
    "# Dependencies:\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from stable_baselines3.common.vec_env.base_vec_env import VecEnv\n",
    "\n",
    "hyperparameters = {\n",
    "    \"n_steps\": 10000,\n",
    "    \"policy_kwargs\": {\n",
    "        \"net_arch\": {\n",
    "            \"pi\": [32, 64, 32],\n",
    "            \"vf\": [32, 64, 32],\n",
    "            \"activation_fn\": \"tanh\",\n",
    "        }\n",
    "    },\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1: Vectorized Environmnent (2 points)\n",
    "\n",
    "#### Overview\n",
    "For any StableBaselines3 algorithm implementation, any gymnasium environment used need to be converted into a [vectorized environment](https://stable-baselines3.readthedocs.io/en/master/guide/vec_envs.html#) of `VecEnv` type. \n",
    "\n",
    "A vectorized environment stacks multiple independent environments into one, stepping multiple `n` environments each time. If we set the the `n_envs` parameter to 3, then 3 environments will be stepped each time the VecEnv is stepped. \n",
    "\n",
    "**For the rest of this assignment, all vectorized environments with n_env=n will be described as n-vectorized.** \n",
    "\n",
    "With a vectorized environment that steps multiple environments at the same time, the model learning process can be made more efficient through parallelization trajectory collection across these independent environments. This `n_envs` parameter can be tailored to the specific machines.  \n",
    "\n",
    "**Import Note of Difference**: \n",
    "- The vectorized environments now require input action to be a shape of `n_envs * act_dim`. The output observation from `step` and `reset` will also have the shape of `n_envs * obs_dim`\n",
    "- The VecEnv `reset()` function returns only the observation, while the gymnasium.Env `reset()` function returns a tuple `(observation, info_dict)` \n",
    "- The `vec_env.step(action)` function returns a 4-tuple of `(obs, reward, terminated, info)`, while the `gym_env.step(action)` returns a 5-tuple of `(obs, reward, terminated, truncated, info)`. The `terminated` value from VecEnv would equivalent to the gymnasium environment's `terminated or truncated` \n",
    "\n",
    " \n",
    "A VecEnv instance can be created using the `make_vec_env` function, which takes the id of the wanted gymnasium environment, as well as the number of environments needed. This function has the following key parameters \n",
    "- `env_id`: required parameter that is the id of the gymnasium environment, or instantiated gym environment, or a callable that returns an env. \n",
    "- `n_envs`: The number of environments to have in parallel \n",
    "- `seed`: The initial seed for the random number generator (This parameter is only here to explain its purpose, for the actual code DO NOT use this parameter)\n",
    "- `env_kwargs`: An optional parameter to pass into the environment constructor. \n",
    "\n",
    "More detailed function documentation can be found in this [page](https://stable-baselines3.readthedocs.io/en/master/common/env_util.html#stable_baselines3.common.env_util.make_vec_env). \n",
    "\n",
    "#### Instructions \n",
    "For this part, please create two vectorized version of MountainCar-v0 with 3 and 1 environments stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "\n",
    "# TODO: \n",
    "real_vec_env_3 = make_vec_env(\"MountainCar-v0\", n_envs=3)\n",
    "real_vec_env_1 = make_vec_env(\"MountainCar-v0\", n_envs=1)\n",
    "# END TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IgB9tsEkrhji"
   },
   "source": [
    "### 1.2: Actor Definition (3 points)\n",
    "\n",
    "**Instruction**: You will need to implement the following PPOActor class, which serves as a wrapper to provide PPO model predictions. \n",
    "- `__init__`: Takes a path to the checkpoint and the corresponding environment, and load an instance of this PPO checkpoint. However if a PPO model is given, then the internally representing model uses that directly instead. This is for use in the Callback function, and since we provide that implementation for you, you will only need to implement the model loading portion of the constructor. \n",
    "\n",
    "**Note**: the environment being passed is usually be the 3-vectorized corresponding environment later in the program, but they will not be used by the actor other than initializing the model. \n",
    "  \n",
    "- `select_action`: Takes an observation and produce the corresponding action prediction from the checkpoint PPO model. While implementing, take note of the output of the `predict` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "DI4B4Ji8rgz5"
   },
   "outputs": [],
   "source": [
    "class PPOActor():\n",
    "    def __init__(self, ckpt: str=None, environment: VecEnv=None, model=None):\n",
    "        '''\n",
    "          Requires environment to be a 1-vectorized environment\n",
    "\n",
    "          The `ckpt` is a .zip file path that leads to the checkpoint you want \n",
    "          to use for this particular actor.  \n",
    "          \n",
    "          If the `model` variable is provided, then this constructor will store\n",
    "          that as the internal representing model instead of loading one from the \n",
    "          checkpoint path\n",
    "          \n",
    "        '''\n",
    "        assert ckpt is not None or model is not None\n",
    "        if model is not None: \n",
    "            self.model = model \n",
    "            return \n",
    "        \n",
    "        # TODO: MODIFY\n",
    "        self.model = PPO.load(ckpt)\n",
    "        # End TODO \n",
    "         \n",
    "    \n",
    "    def select_action(self, obs):\n",
    "        '''\n",
    "          Gives the action prediction of this particular actor \n",
    "        '''\n",
    "        # TODO:\n",
    "        action, _ = self.model.predict(obs)\n",
    "        return action\n",
    "        # END TODO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RBYVvwAJn1O2"
   },
   "source": [
    "### 1.3: [PROVIDED] Callbacks\n",
    "\n",
    "To visualize the training process, since it could take a significant amount of time, StableBaselines3 provides a mean for us to visualize the training progress through a BaseCallback class instance, which can be optionally passed in as a parameter of the `learn` function. This Callback function is customizable by defining a subclass of `BaseCallback`. \n",
    "\n",
    "For this part, we provide you with a customized callback that evaluates the model under training every 120000 steps on an evaluating environment, which will be the 1-vectorized environment you have instantiated in the previous portion. Based on this evaluation result, this callback will save a checkpoint of the model if it is, so far, the best performing model. At the end of training, a plot of all evaluation results with respect to number of steps will be generated. \n",
    "\n",
    "You are free to modify this callback class to help you visualize training in any way most convenient for you, but is **NOT REQUIRED**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "B2lI5ctYnLI4"
   },
   "outputs": [],
   "source": [
    "class PPOCallback(BaseCallback):\n",
    "    def __init__(self, verbose=0, save_path='default', eval_env=None):\n",
    "        super(PPOCallback, self).__init__(verbose)\n",
    "        self.rewards = []\n",
    "\n",
    "        self.save_freq = 120000\n",
    "        self.min_reward = -np.inf\n",
    "        self.actor = None\n",
    "        self.eval_env = eval_env \n",
    "        \n",
    "        self.save_path = save_path\n",
    "\n",
    "        self.eval_steps = []\n",
    "        self.eval_rewards = [] \n",
    "\n",
    "    def _init_callback(self) -> None:\n",
    "        pass \n",
    "\n",
    "    def _on_training_start(self) -> None:\n",
    "        \"\"\"\n",
    "        This method is called before the first rollout starts.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.actor = PPOActor(model=self.model)\n",
    "\n",
    "    def _on_rollout_start(self) -> None: \n",
    "        \"\"\"\n",
    "        A rollout is the collection of environment interaction\n",
    "        using the current policy.\n",
    "        This event is triggered before collecting new samples.\n",
    "        \"\"\"\n",
    "        pass \n",
    "\n",
    "    def _on_rollout_end(self) -> None:\n",
    "        \"\"\"\n",
    "        This event is triggered before updating the policy.\n",
    "        \"\"\"\n",
    "\n",
    "        episode_info = self.model.ep_info_buffer\n",
    "        rewards = [ep_info['r'] for ep_info in episode_info]\n",
    "        mean_rewards = np.mean(rewards)\n",
    "\n",
    "        self.rewards.append(mean_rewards)\n",
    "        \n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        \"\"\"\n",
    "        This method will be called by the model after each call to `env.step()`.\n",
    "\n",
    "        For child callback (of an `EventCallback`), this will be called\n",
    "        when the event is triggered.\n",
    "\n",
    "        :return: If the callback returns False, training is aborted early.\n",
    "        \"\"\"\n",
    "        if self.eval_env is None: \n",
    "            return True \n",
    "\n",
    "        if self.num_timesteps % self.save_freq == 0 and self.num_timesteps != 0: \n",
    "            mean_reward = evaluate_policy(self.actor, environment=self.eval_env, num_episodes=20) \n",
    "            print(f'evaluating {self.num_timesteps=}, {mean_reward=}=======')\n",
    "\n",
    "            self.eval_steps.append(self.num_timesteps)\n",
    "            self.eval_rewards.append(mean_reward)\n",
    "            if mean_reward > self.min_reward: \n",
    "                self.min_reward = mean_reward \n",
    "                self.model.save(self.save_path)\n",
    "                print(f'model saved on eval reward: {self.min_reward}')\n",
    "        \n",
    "        return True\n",
    "\n",
    "    def _on_training_end(self) -> None:\n",
    "        \"\"\"\n",
    "        This event is triggered before exiting the `learn()` method.\n",
    "        \"\"\"\n",
    "        print(f'model saved on eval reward: {self.min_reward}')\n",
    "\n",
    "        plt.plot(self.eval_steps, self.eval_rewards, c='red')\n",
    "        plt.xlabel('Episodes')\n",
    "        plt.ylabel('Rewards')\n",
    "        plt.title('Rewards over Episodes')\n",
    "\n",
    "        plt.show()\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fy2goV7lPAc4"
   },
   "source": [
    "### 1.4 PPO Expert Initialization and Training (2 points)\n",
    "\n",
    "#### Overview\n",
    "\n",
    "The `stable_baselines3.ppo.PPO` class inherits from the `BaseAlgorithm` class described at the beginning of this section, and is specifically implemented for the PPO algorithm. To initialize a class, the following parameters are especially important: \n",
    "- `policy: str`: The policy type we use to train the agent, common ones include MlpPolicy and CnnPolicy. In our case, we will be using the MlpPolicy. \n",
    "- `env: VecEnv`: The environment that the agent rollouts on for training, must be vectorized or it will be vectorized by the PPO implementation \n",
    "- `n_steps`: number of steps to optimize the policy for \n",
    "- `device`: The device to put the model on (For this assignment, if you're not able to reach the performance bounds, try setting this parameter to cpu)\n",
    "- Other hyperparameters specified in the `hyperparameters` dictionary we provided, can be directly applied using the \\*\\* operator. \n",
    "\n",
    "#### Instructions \n",
    "- Initialize a PPO MLP policy as expert, using the 3-env VecEnv initialized in the previous part and pass in the given hyperparameters. \n",
    "- Train the expert with an instance of the `PPOCallback` defined before. No need to save the resulting model into checkpoint since that is done for you in the Callback class\n",
    "    \n",
    "    (HINT): Look at the beginning of Part 1 for useful functions for training. \n",
    "\n",
    "\n",
    "**Estimated Training Time**: \n",
    "- 10 minutes on a Mac M1 CPU\n",
    "- 30 minutes on Google Colab CPU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eOFH-zYzPAc5",
    "outputId": "fa966b97-507c-4a45-bac0-0755b3636b1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/cs4756_a5/lib/python3.10/site-packages/stable_baselines3/ppo/ppo.py:155: UserWarning: You have specified a mini-batch size of 64, but because the `RolloutBuffer` is of size `n_steps * n_envs = 30000`, after every 468 untruncated mini-batches, there will be a truncated mini-batch of size 48\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=10000 and n_envs=3)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -200     |\n",
      "| time/              |          |\n",
      "|    fps             | 12245    |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 30000    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -200         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 4660         |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 12           |\n",
      "|    total_timesteps      | 60000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008778124 |\n",
      "|    clip_fraction        | 3.33e-06     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.1         |\n",
      "|    explained_variance   | -0.000189    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.51         |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -4.16e-05    |\n",
      "|    value_loss           | 20.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -200         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 4044         |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 22           |\n",
      "|    total_timesteps      | 90000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012799442 |\n",
      "|    clip_fraction        | 3e-05        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.1         |\n",
      "|    explained_variance   | 2.23e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.06         |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.000172    |\n",
      "|    value_loss           | 22.1         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 28.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating self.num_timesteps=120000, mean_reward=-200.0=======\n",
      "model saved on eval reward: -200.0\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -200         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3630         |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 33           |\n",
      "|    total_timesteps      | 120000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074338582 |\n",
      "|    clip_fraction        | 0.00659      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | 0.00401      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.43         |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.000256    |\n",
      "|    value_loss           | 13.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -200         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3490         |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 42           |\n",
      "|    total_timesteps      | 150000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059836223 |\n",
      "|    clip_fraction        | 0.00498      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | -0.00273     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.96         |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.000169    |\n",
      "|    value_loss           | 8.53         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -200        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3400        |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 52          |\n",
      "|    total_timesteps      | 180000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013504675 |\n",
      "|    clip_fraction        | 0.045       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | 0.00446     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.2         |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.00232    |\n",
      "|    value_loss           | 5.56        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -200         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3343         |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 62           |\n",
      "|    total_timesteps      | 210000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051367474 |\n",
      "|    clip_fraction        | 0.0114       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.998       |\n",
      "|    explained_variance   | 0.0163       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.261        |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -3.98e-05    |\n",
      "|    value_loss           | 3.51         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 27.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating self.num_timesteps=240000, mean_reward=-200.0=======\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -200        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3255        |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 73          |\n",
      "|    total_timesteps      | 240000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002008133 |\n",
      "|    clip_fraction        | 0.00569     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.03       |\n",
      "|    explained_variance   | 0.0277      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.452       |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.000124   |\n",
      "|    value_loss           | 2.26        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -200        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3212        |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 84          |\n",
      "|    total_timesteps      | 270000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005970496 |\n",
      "|    clip_fraction        | 0.00444     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | 0.0251      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.402       |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.000206   |\n",
      "|    value_loss           | 1.49        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -200        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3184        |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 94          |\n",
      "|    total_timesteps      | 300000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010346375 |\n",
      "|    clip_fraction        | 0.0181      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.994      |\n",
      "|    explained_variance   | 0.0151      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.393       |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.00056    |\n",
      "|    value_loss           | 0.986       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -200        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3154        |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 104         |\n",
      "|    total_timesteps      | 330000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011566087 |\n",
      "|    clip_fraction        | 0.0416      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.895      |\n",
      "|    explained_variance   | 0.0526      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.275       |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.00228    |\n",
      "|    value_loss           | 0.673       |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 27.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating self.num_timesteps=360000, mean_reward=-200.0=======\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -200         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3104         |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 115          |\n",
      "|    total_timesteps      | 360000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050748284 |\n",
      "|    clip_fraction        | 0.0246       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.824       |\n",
      "|    explained_variance   | 0.0412       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.177        |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.000811    |\n",
      "|    value_loss           | 0.439        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -200         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3083         |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 126          |\n",
      "|    total_timesteps      | 390000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039492464 |\n",
      "|    clip_fraction        | 0.0125       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.779       |\n",
      "|    explained_variance   | 0.0536       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.205        |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.00062     |\n",
      "|    value_loss           | 0.298        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -200         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3051         |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 137          |\n",
      "|    total_timesteps      | 420000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059872647 |\n",
      "|    clip_fraction        | 0.0208       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.697       |\n",
      "|    explained_variance   | 0.0931       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.1          |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.000909    |\n",
      "|    value_loss           | 0.202        |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 200        |\n",
      "|    ep_rew_mean          | -200       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 3049       |\n",
      "|    iterations           | 15         |\n",
      "|    time_elapsed         | 147        |\n",
      "|    total_timesteps      | 450000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00493926 |\n",
      "|    clip_fraction        | 0.023      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.623     |\n",
      "|    explained_variance   | 0.126      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.00759    |\n",
      "|    n_updates            | 140        |\n",
      "|    policy_gradient_loss | -0.0012    |\n",
      "|    value_loss           | 0.137      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 28.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating self.num_timesteps=480000, mean_reward=-200.0=======\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -200        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3033        |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 158         |\n",
      "|    total_timesteps      | 480000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004115345 |\n",
      "|    clip_fraction        | 0.0178      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.557      |\n",
      "|    explained_variance   | 0.11        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0352      |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.000622   |\n",
      "|    value_loss           | 0.0947      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -200        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3037        |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 167         |\n",
      "|    total_timesteps      | 510000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002961591 |\n",
      "|    clip_fraction        | 0.0137      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.506      |\n",
      "|    explained_variance   | 0.191       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0259      |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.000487   |\n",
      "|    value_loss           | 0.0681      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -200         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3041         |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 177          |\n",
      "|    total_timesteps      | 540000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028906164 |\n",
      "|    clip_fraction        | 0.0239       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.435       |\n",
      "|    explained_variance   | 0.25         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0139       |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.00112     |\n",
      "|    value_loss           | 0.0495       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -200         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3047         |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 187          |\n",
      "|    total_timesteps      | 570000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027268229 |\n",
      "|    clip_fraction        | 0.0281       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.382       |\n",
      "|    explained_variance   | 0.266        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0164       |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.00166     |\n",
      "|    value_loss           | 0.0326       |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 28.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating self.num_timesteps=600000, mean_reward=-200.0=======\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -200         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3041         |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 197          |\n",
      "|    total_timesteps      | 600000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013387813 |\n",
      "|    clip_fraction        | 0.0155       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.355       |\n",
      "|    explained_variance   | 0.441        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00382      |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.000839    |\n",
      "|    value_loss           | 0.0252       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -200         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3044         |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 206          |\n",
      "|    total_timesteps      | 630000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008353907 |\n",
      "|    clip_fraction        | 0.00878      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.339       |\n",
      "|    explained_variance   | 0.558        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.000727    |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.000568    |\n",
      "|    value_loss           | 0.0168       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -200         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3049         |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 216          |\n",
      "|    total_timesteps      | 660000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007996696 |\n",
      "|    clip_fraction        | 0.0103       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.324       |\n",
      "|    explained_variance   | 0.768        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00882      |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.000838    |\n",
      "|    value_loss           | 0.0143       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -200         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3052         |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 226          |\n",
      "|    total_timesteps      | 690000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014749801 |\n",
      "|    clip_fraction        | 0.0238       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.275       |\n",
      "|    explained_variance   | 0.852        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.011        |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -0.00068     |\n",
      "|    value_loss           | 0.016        |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 29.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating self.num_timesteps=720000, mean_reward=-200.0=======\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -200        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3042        |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 236         |\n",
      "|    total_timesteps      | 720000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001325083 |\n",
      "|    clip_fraction        | 0.0124      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.313      |\n",
      "|    explained_variance   | 0.909       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00593     |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.00174    |\n",
      "|    value_loss           | 0.0204      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -200        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3045        |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 246         |\n",
      "|    total_timesteps      | 750000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005419237 |\n",
      "|    clip_fraction        | 0.0399      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.322      |\n",
      "|    explained_variance   | 0.958       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0104      |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.00446    |\n",
      "|    value_loss           | 0.0162      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -200         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3049         |\n",
      "|    iterations           | 26           |\n",
      "|    time_elapsed         | 255          |\n",
      "|    total_timesteps      | 780000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035920423 |\n",
      "|    clip_fraction        | 0.0461       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.326       |\n",
      "|    explained_variance   | 0.972        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.022        |\n",
      "|    n_updates            | 250          |\n",
      "|    policy_gradient_loss | -0.00676     |\n",
      "|    value_loss           | 0.0372       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 199         |\n",
      "|    ep_rew_mean          | -199        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3050        |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 265         |\n",
      "|    total_timesteps      | 810000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012454069 |\n",
      "|    clip_fraction        | 0.0888      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.361      |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00422     |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.00986    |\n",
      "|    value_loss           | 0.103       |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 28.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating self.num_timesteps=840000, mean_reward=-198.0500030517578=======\n",
      "model saved on eval reward: -198.0500030517578\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 196         |\n",
      "|    ep_rew_mean          | -196        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3044        |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 275         |\n",
      "|    total_timesteps      | 840000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007790913 |\n",
      "|    clip_fraction        | 0.0717      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.445      |\n",
      "|    explained_variance   | 0.916       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.525       |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.00691    |\n",
      "|    value_loss           | 2.27        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 187         |\n",
      "|    ep_rew_mean          | -187        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3046        |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 285         |\n",
      "|    total_timesteps      | 870000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006589851 |\n",
      "|    clip_fraction        | 0.0902      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.478      |\n",
      "|    explained_variance   | 0.913       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.75        |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.00584    |\n",
      "|    value_loss           | 7.27        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 163         |\n",
      "|    ep_rew_mean          | -163        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3049        |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 295         |\n",
      "|    total_timesteps      | 900000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006992391 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.481      |\n",
      "|    explained_variance   | 0.94        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.58        |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.00576    |\n",
      "|    value_loss           | 9.64        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 155         |\n",
      "|    ep_rew_mean          | -155        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3051        |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 304         |\n",
      "|    total_timesteps      | 930000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009746802 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.453      |\n",
      "|    explained_variance   | 0.956       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.89        |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.00478    |\n",
      "|    value_loss           | 10.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 39.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating self.num_timesteps=960000, mean_reward=-145.75=======\n",
      "model saved on eval reward: -145.75\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 144        |\n",
      "|    ep_rew_mean          | -144       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 3048       |\n",
      "|    iterations           | 32         |\n",
      "|    time_elapsed         | 314        |\n",
      "|    total_timesteps      | 960000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00981593 |\n",
      "|    clip_fraction        | 0.107      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.428     |\n",
      "|    explained_variance   | 0.976      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.95       |\n",
      "|    n_updates            | 310        |\n",
      "|    policy_gradient_loss | -0.00752   |\n",
      "|    value_loss           | 8.75       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 132         |\n",
      "|    ep_rew_mean          | -132        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3050        |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 324         |\n",
      "|    total_timesteps      | 990000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021363752 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.345      |\n",
      "|    explained_variance   | 0.98        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.26        |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.00865    |\n",
      "|    value_loss           | 5.77        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 127         |\n",
      "|    ep_rew_mean          | -127        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3050        |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 334         |\n",
      "|    total_timesteps      | 1020000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013679726 |\n",
      "|    clip_fraction        | 0.0801      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.271      |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.28        |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.00396    |\n",
      "|    value_loss           | 4.73        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 119         |\n",
      "|    ep_rew_mean          | -119        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3048        |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 344         |\n",
      "|    total_timesteps      | 1050000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005339058 |\n",
      "|    clip_fraction        | 0.0525      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.236      |\n",
      "|    explained_variance   | 0.977       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.04        |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.00167    |\n",
      "|    value_loss           | 4.42        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 46.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating self.num_timesteps=1080000, mean_reward=-118.80000305175781=======\n",
      "model saved on eval reward: -118.80000305175781\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 120         |\n",
      "|    ep_rew_mean          | -120        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3043        |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 354         |\n",
      "|    total_timesteps      | 1080000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004794683 |\n",
      "|    clip_fraction        | 0.0443      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.191      |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.62        |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.000947   |\n",
      "|    value_loss           | 2.87        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 119          |\n",
      "|    ep_rew_mean          | -119         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3042         |\n",
      "|    iterations           | 37           |\n",
      "|    time_elapsed         | 364          |\n",
      "|    total_timesteps      | 1110000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039159153 |\n",
      "|    clip_fraction        | 0.0382       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.183       |\n",
      "|    explained_variance   | 0.986        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.38         |\n",
      "|    n_updates            | 360          |\n",
      "|    policy_gradient_loss | -0.0019      |\n",
      "|    value_loss           | 3.34         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 116          |\n",
      "|    ep_rew_mean          | -116         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3046         |\n",
      "|    iterations           | 38           |\n",
      "|    time_elapsed         | 374          |\n",
      "|    total_timesteps      | 1140000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032514685 |\n",
      "|    clip_fraction        | 0.0361       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.166       |\n",
      "|    explained_variance   | 0.991        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.68         |\n",
      "|    n_updates            | 370          |\n",
      "|    policy_gradient_loss | -0.000757    |\n",
      "|    value_loss           | 2.38         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 112          |\n",
      "|    ep_rew_mean          | -112         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3048         |\n",
      "|    iterations           | 39           |\n",
      "|    time_elapsed         | 383          |\n",
      "|    total_timesteps      | 1170000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042922287 |\n",
      "|    clip_fraction        | 0.0325       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.135       |\n",
      "|    explained_variance   | 0.994        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.768        |\n",
      "|    n_updates            | 380          |\n",
      "|    policy_gradient_loss | 0.000118     |\n",
      "|    value_loss           | 1.54         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 53.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating self.num_timesteps=1200000, mean_reward=-105.75=======\n",
      "model saved on eval reward: -105.75\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 113          |\n",
      "|    ep_rew_mean          | -113         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3048         |\n",
      "|    iterations           | 40           |\n",
      "|    time_elapsed         | 393          |\n",
      "|    total_timesteps      | 1200000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066197054 |\n",
      "|    clip_fraction        | 0.0442       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.122       |\n",
      "|    explained_variance   | 0.997        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.315        |\n",
      "|    n_updates            | 390          |\n",
      "|    policy_gradient_loss | -0.00306     |\n",
      "|    value_loss           | 0.582        |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 110          |\n",
      "|    ep_rew_mean          | -110         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3051         |\n",
      "|    iterations           | 41           |\n",
      "|    time_elapsed         | 403          |\n",
      "|    total_timesteps      | 1230000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052325362 |\n",
      "|    clip_fraction        | 0.0391       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.117       |\n",
      "|    explained_variance   | 0.996        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.305        |\n",
      "|    n_updates            | 400          |\n",
      "|    policy_gradient_loss | 0.000484     |\n",
      "|    value_loss           | 1.23         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 111         |\n",
      "|    ep_rew_mean          | -111        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3052        |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 412         |\n",
      "|    total_timesteps      | 1260000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007000833 |\n",
      "|    clip_fraction        | 0.0459      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.107      |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.124       |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.00349    |\n",
      "|    value_loss           | 0.406       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 106         |\n",
      "|    ep_rew_mean          | -106        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3052        |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 422         |\n",
      "|    total_timesteps      | 1290000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003778175 |\n",
      "|    clip_fraction        | 0.0216      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0926     |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 13.3        |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | 0.000442    |\n",
      "|    value_loss           | 2.06        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 54.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating self.num_timesteps=1320000, mean_reward=-108.30000305175781=======\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 109          |\n",
      "|    ep_rew_mean          | -109         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3053         |\n",
      "|    iterations           | 44           |\n",
      "|    time_elapsed         | 432          |\n",
      "|    total_timesteps      | 1320000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036855405 |\n",
      "|    clip_fraction        | 0.025        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0672      |\n",
      "|    explained_variance   | 0.997        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.125        |\n",
      "|    n_updates            | 430          |\n",
      "|    policy_gradient_loss | 1.32e-05     |\n",
      "|    value_loss           | 1.12         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 107         |\n",
      "|    ep_rew_mean          | -107        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3058        |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 441         |\n",
      "|    total_timesteps      | 1350000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017795486 |\n",
      "|    clip_fraction        | 0.0523      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0821     |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.071       |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.00637    |\n",
      "|    value_loss           | 0.219       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 110          |\n",
      "|    ep_rew_mean          | -110         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3063         |\n",
      "|    iterations           | 46           |\n",
      "|    time_elapsed         | 450          |\n",
      "|    total_timesteps      | 1380000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035890464 |\n",
      "|    clip_fraction        | 0.0255       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0669      |\n",
      "|    explained_variance   | 0.997        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.221        |\n",
      "|    n_updates            | 450          |\n",
      "|    policy_gradient_loss | 0.000163     |\n",
      "|    value_loss           | 0.826        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 109          |\n",
      "|    ep_rew_mean          | -109         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3065         |\n",
      "|    iterations           | 47           |\n",
      "|    time_elapsed         | 459          |\n",
      "|    total_timesteps      | 1410000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043614674 |\n",
      "|    clip_fraction        | 0.0205       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0635      |\n",
      "|    explained_variance   | 0.995        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.173        |\n",
      "|    n_updates            | 460          |\n",
      "|    policy_gradient_loss | 0.00134      |\n",
      "|    value_loss           | 1.56         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 50.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating self.num_timesteps=1440000, mean_reward=-110.44999694824219=======\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 106         |\n",
      "|    ep_rew_mean          | -106        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3066        |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 469         |\n",
      "|    total_timesteps      | 1440000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008475549 |\n",
      "|    clip_fraction        | 0.0208      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0591     |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.599       |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | 0.00127     |\n",
      "|    value_loss           | 1.92        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 105         |\n",
      "|    ep_rew_mean          | -105        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3070        |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 478         |\n",
      "|    total_timesteps      | 1470000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010948516 |\n",
      "|    clip_fraction        | 0.0202      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0535     |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.42        |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | 0.00138     |\n",
      "|    value_loss           | 2.19        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 104          |\n",
      "|    ep_rew_mean          | -104         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3074         |\n",
      "|    iterations           | 50           |\n",
      "|    time_elapsed         | 487          |\n",
      "|    total_timesteps      | 1500000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029370424 |\n",
      "|    clip_fraction        | 0.0225       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0533      |\n",
      "|    explained_variance   | 0.997        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0917       |\n",
      "|    n_updates            | 490          |\n",
      "|    policy_gradient_loss | 3.09e-06     |\n",
      "|    value_loss           | 0.544        |\n",
      "------------------------------------------\n",
      "model saved on eval reward: -105.75\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkcAAAHHCAYAAAC1G/yyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAABPCElEQVR4nO3deVxUVf8H8M+wDciubCqkgoo7LqSBoriSmsvzK3cL91Qs10wfS7MyMpeyNJcysTJzN8slLfVRjEwRzA3cUBQDJWURkPX8/rjNNCOoMM7MnYHP+/WaF3fu3Lnz5Vjw4dxzzlUIIQSIiIiICABgIXcBRERERKaE4YiIiIhIA8MRERERkQaGIyIiIiINDEdEREREGhiOiIiIiDQwHBERERFpYDgiIiIi0sBwRERERKSB4YiIZKNQKPDOO+/IXYZZu3btGhQKBaKiooz6uaGhoQgNDTXqZxIZC8MRkQmKioqCQqFQP6ysrFC7dm2MGDECKSkpcpdHT0Hz3/Xhx/jx4+Uuj4gAWMldABE92rvvvot69erhwYMH+P333xEVFYXo6GicPXsWtra2cpdHOurevTteeeWVUvsbNmxY4XPVqVMHeXl5sLa21kdpRASGIyKT1rNnTwQGBgIAxowZAzc3NyxcuBC7du3CwIEDZa7uyXJycmBvby93GUb14MED2NjYwMLi0R3zDRs2xPDhw/XyeQqFgkGZSM94WY3IjISEhAAArly5orU/ISEBL730EqpXrw5bW1sEBgZi165d6tczMjJgaWmJTz/9VL0vPT0dFhYWqFGjBoQQ6v0TJkyAl5eX+vnRo0cxYMAAPPPMM1AqlfDx8cHUqVORl5enVcOIESPg4OCAK1euoFevXnB0dMSwYcMAAPn5+Zg6dSrc3d3h6OiIvn374ubNm6W+v+zsbEyZMgV169aFUqmEh4cHunfvjlOnTj2xbeLi4tCzZ084OTnBwcEBXbt2xe+//65+/eTJk1AoFFi/fn2p9/78889QKBT46aef1PtSUlIwatQoeHp6QqlUomnTpvjqq6+03nf48GEoFAp8//33eOutt1C7dm1Uq1YNWVlZT6z3SUJDQ9GsWTPExsYiODgYdnZ2qFevHlatWqV1XFljjlJTUzFy5Eh4e3tDqVSiZs2a6NevH65du6b13s8//xxNmzaFUqlErVq1EBERgYyMjFK1rFmzBn5+frCzs0Pbtm1x9OjRMmvOz8/HvHnzUL9+ffV/KzNnzkR+fr7WcQcOHECHDh3g4uICBwcH+Pv747///a9O7URkCOw5IjIjql9urq6u6n3nzp1D+/btUbt2bcyaNQv29vbYvHkz+vfvj23btuE///kPXFxc0KxZMxw5cgSvv/46ACA6OhoKhQJ3797F+fPn0bRpUwBSGFKFMADYsmULcnNzMWHCBNSoUQN//PEHPvvsM9y8eRNbtmzRqq+oqAhhYWHo0KEDFi9ejGrVqgGQer2+/fZbDB06FMHBwTh48CB69+5d6vsbP348tm7dikmTJqFJkyb4+++/ER0djQsXLqB169aPbJdz584hJCQETk5OmDlzJqytrbF69WqEhobif//7H9q1a4fAwED4+vpi8+bNCA8P13r/pk2b4OrqirCwMABAWloannvuOSgUCkyaNAnu7u7Yu3cvRo8ejaysLEyZMkXr/e+99x5sbGwwY8YM5Ofnw8bG5nH/jHjw4AHS09NL7XdyctJ6771799CrVy8MHDgQQ4YMwebNmzFhwgTY2Nhg1KhRjzz/iy++iHPnzuG1115D3bp1cfv2bRw4cADJycmoW7cuAOCdd97B/Pnz0a1bN0yYMAGJiYlYuXIlTpw4gWPHjqkv061duxavvvoqgoODMWXKFFy9ehV9+/ZF9erV4ePjo/7MkpIS9O3bF9HR0Rg3bhwaN26MM2fO4OOPP8bFixexc+dO9b/VCy+8gBYtWuDdd9+FUqnE5cuXcezYsce2GZFRCSIyOevWrRMAxC+//CLu3Lkjbty4IbZu3Src3d2FUqkUN27cUB/btWtX0bx5c/HgwQP1vpKSEhEcHCwaNGig3hcRESE8PT3Vz6dNmyY6duwoPDw8xMqVK4UQQvz9999CoVCIZcuWqY/Lzc0tVV9kZKRQKBTi+vXr6n3h4eECgJg1a5bWsfHx8QKAmDhxotb+oUOHCgBi3rx56n3Ozs4iIiKivM2k1r9/f2FjYyOuXLmi3nfr1i3h6OgoOnbsqN43e/ZsYW1tLe7evavel5+fL1xcXMSoUaPU+0aPHi1q1qwp0tPTtT5n8ODBwtnZWd0mhw4dEgCEr69vme1UFgCPfGzcuFF9XKdOnQQAsWTJEq1aW7ZsKTw8PERBQYEQQoikpCQBQKxbt04IIcS9e/cEALFo0aJH1nD79m1hY2MjevToIYqLi9X7ly9fLgCIr776SgghREFBgfDw8BAtW7YU+fn56uPWrFkjAIhOnTqp933zzTfCwsJCHD16VOuzVq1aJQCIY8eOCSGE+PjjjwUAcefOnXK1F5EceFmNyIR169YN7u7u8PHxwUsvvQR7e3vs2rUL3t7eAIC7d+/i4MGDGDhwILKzs5Geno709HT8/fffCAsLw6VLl9Sz20JCQpCWlobExEQAUg9Rx44dERISor5MEh0dDSGEVs+RnZ2dejsnJwfp6ekIDg6GEAJxcXGlap4wYYLW8z179gCAusdK5eHeFwBwcXHB8ePHcevWrXK3UXFxMfbv34/+/fvD19dXvb9mzZoYOnQooqOj1Ze5Bg0ahMLCQmzfvl193P79+5GRkYFBgwYBAIQQ2LZtG/r06QMhhLpN09PTERYWhszMzFKX+cLDw7Xa6Un69euHAwcOlHp07txZ6zgrKyu8+uqr6uc2NjZ49dVXcfv2bcTGxpZ5bjs7O9jY2ODw4cO4d+9emcf88ssvKCgowJQpU7TGRo0dOxZOTk7YvXs3AOlS5O3btzF+/HitHq0RI0bA2dlZ65xbtmxB48aN0ahRI60269KlCwDg0KFDAKR/YwD44YcfUFJSUp7mIjI6hiMiE7ZixQocOHAAW7duRa9evZCeng6lUql+/fLlyxBC4O2334a7u7vWY968eQCA27dvA/h3vNLRo0eRk5ODuLg4hISEoGPHjupwdPToUTg5OSEgIED9GcnJyRgxYgSqV68OBwcHuLu7o1OnTgCAzMxMrXqtrKzUwU3l+vXrsLCwgJ+fn9Z+f3//Ut/vRx99hLNnz8LHxwdt27bFO++8g6tXrz62je7cuYPc3Nwyz9e4cWOUlJTgxo0bAICAgAA0atQImzZtUh+zadMmuLm5qX+J37lzBxkZGVizZk2pNh05cqRWm6rUq1fvsTU+zNvbG926dSv18PT01DquVq1apQa0q2a0PTx+SEWpVGLhwoXYu3cvPD090bFjR3z00UdITU1VH3P9+nUApf8NbGxs4Ovrq35d9bVBgwZax1lbW2sFUQC4dOkSzp07V6rNVPWq2mzQoEFo3749xowZA09PTwwePBibN29mUCKTwjFHRCasbdu26tlq/fv3R4cOHTB06FAkJibCwcFB/QtlxowZ6vEyD6tfvz4A6RdtvXr1cOTIEdStWxdCCAQFBcHd3R2TJ0/G9evXcfToUQQHB6t7E4qLi9G9e3fcvXsXb775Jho1agR7e3ukpKRgxIgRpX6hKZXKx87SepKBAwciJCQEO3bswP79+7Fo0SIsXLgQ27dvR8+ePXU+r6ZBgwZhwYIFSE9Ph6OjI3bt2oUhQ4bAykr6caj6noYPH15qbJJKixYttJ5XpNfIGKZMmYI+ffpg586d+Pnnn/H2228jMjISBw8eRKtWrQzymSUlJWjevDmWLl1a5uuq8Ul2dnY4cuQIDh06hN27d2Pfvn3YtGkTunTpgv3798PS0tIg9RFVBMMRkZmwtLREZGQkOnfujOXLl2PWrFnqv96tra3RrVu3J54jJCQER44cQb169dCyZUs4OjoiICAAzs7O2LdvH06dOoX58+erjz9z5gwuXryI9evXa63Lc+DAgXLXXadOHZSUlODKlStaPRWqy3sPq1mzJiZOnIiJEyfi9u3baN26NRYsWPDIcOTu7o5q1aqVeb6EhARYWFhoDRweNGgQ5s+fj23btsHT0xNZWVkYPHiw1vkcHR1RXFxcrjY1pFu3bpVaDuHixYsAoB5Y/Sh+fn6YPn06pk+fjkuXLqFly5ZYsmQJvv32W9SpUweA9G+g2QNUUFCApKQk9fetOu7SpUvqnjUAKCwsRFJSklYPo5+fH06fPo2uXbtCoVA8tjYLCwt07doVXbt2xdKlS/HBBx9gzpw5OHTokOxtTgTwshqRWQkNDUXbtm3xySef4MGDB/Dw8EBoaChWr16Nv/76q9Txd+7c0XoeEhKCa9euYdOmTerLbBYWFggODsbSpUtRWFioNd5I9Ve80JjqL4TAsmXLyl2zKtRoLiMAAJ988onW8+Li4lKX6Tw8PFCrVq1SU8E1WVpaokePHvjhhx+0LjWlpaXhu+++Q4cOHeDk5KTe37hxYzRv3hybNm3Cpk2bULNmTXTs2FHrfC+++CK2bduGs2fPlvq8h9vUkIqKirB69Wr184KCAqxevRru7u5o06ZNme/Jzc3FgwcPtPb5+fnB0dFR3Y7dunWDjY0NPv30U61/27Vr1yIzM1M9kzAwMBDu7u5YtWoVCgoK1MdFRUWVmvI/cOBApKSk4IsvvihVU15eHnJycgBI4+Qe1rJlSwB47L8zkTGx54jIzLzxxhsYMGAAoqKiMH78eKxYsQIdOnRA8+bNMXbsWPj6+iItLQ0xMTG4efMmTp8+rX6vKvgkJibigw8+UO/v2LEj9u7dC6VSiWeffVa9v1GjRvDz88OMGTOQkpICJycnbNu27ZEDfcvSsmVLDBkyBJ9//jkyMzMRHByMX3/9FZcvX9Y6Ljs7G97e3njppZcQEBAABwcH/PLLLzhx4gSWLFny2M94//331WvnTJw4EVZWVli9ejXy8/Px0UcflTp+0KBBmDt3LmxtbTF69OhSlwI//PBDHDp0CO3atcPYsWPRpEkT3L17F6dOncIvv/xS5i/4irh48SK+/fbbUvs9PT3RvXt39fNatWph4cKFuHbtGho2bIhNmzYhPj4ea9aseeSK2BcvXkTXrl0xcOBANGnSBFZWVtixYwfS0tLUPWTu7u6YPXs25s+fj+effx59+/ZFYmIiPv/8czz77LPqBSqtra3x/vvv49VXX0WXLl0waNAgJCUlYd26daXGHL388svYvHkzxo8fj0OHDqF9+/YoLi5GQkICNm/ejJ9//hmBgYF49913ceTIEfTu3Rt16tTB7du38fnnn8Pb2xsdOnR4qnYl0hvZ5skR0SOppvKfOHGi1GvFxcXCz89P+Pn5iaKiIiGEEFeuXBGvvPKK8PLyEtbW1qJ27drihRdeEFu3bi31fg8PDwFApKWlqfdFR0cLACIkJKTU8efPnxfdunUTDg4Ows3NTYwdO1acPn1aa/q4ENJUfnt7+zK/n7y8PPH666+LGjVqCHt7e9GnTx9x48YNran8+fn54o033hABAQHC0dFR2Nvbi4CAAPH555+Xq81OnTolwsLChIODg6hWrZro3Lmz+O2338o89tKlS+rp89HR0WUek5aWJiIiIoSPj4+wtrYWXl5eomvXrmLNmjXqY1RT+bds2VKuGoV4/FR+zanxnTp1Ek2bNhUnT54UQUFBwtbWVtSpU0csX75c63wPT+VPT08XERERolGjRsLe3l44OzuLdu3aic2bN5eqZfny5aJRo0bC2tpaeHp6igkTJoh79+6VOu7zzz8X9erVE0qlUgQGBoojR46ITp06adUrhDT1f+HChaJp06ZCqVQKV1dX0aZNGzF//nyRmZkphBDi119/Ff369RO1atUSNjY2olatWmLIkCHi4sWL5W5DIkNTCKHRp0pERCYhNDQU6enpZV7aIyLD4pgjIiIiIg0MR0REREQaGI6IiIiINHDMEREREZEG9hwRERERaWA4IiIiItLARSArqKSkBLdu3YKjo+MTl8gnIiIi0yCEQHZ2NmrVqvXEe0AyHFXQrVu3tO7TRERERObjxo0b8Pb2fuwxDEcV5OjoCEBqXM37NREREZHpysrKgo+Pj/r3+OMwHFWQ6lKak5MTwxEREZGZKc+QGA7IJiIiItLAcERERESkgeGIiIiISAPDEREREZEGhiMiIiIiDQxHRERERBoYjoiIiIg0MBwRERERaWA4IiIiItLAcERERESkgeGIiIiISAPDEREREZEGhiMiIiJ9yM0FHjyQuwrSA4YjIiKip3XqFFC7NuDkBLRrB0yZAnz/PXD9OiCE3NVRBSmE4L9aRWRlZcHZ2RmZmZlwcnKSuxwiIpLbtWtAUBCQmlr26zVrSq8/95z0tU0bwM7OqCVSxX5/MxxVEMMRERGp3b0LtG8PJCQAzZsD330H/PknEBMjPU6fBoqKtN9jZQW0avVvWAoKAurUARQKeb6HKoLhyIAYjoiICIA0vqhHD+DoUcDbWwpD3t7ax+TmArGx/4almBggLa30uby8tHuXAgPZu6RnDEcGxHBEREQoKQGGDAE2bwacnYHoaKBZsye/TwhpHJIqKP3+OxAXV3bvUsuW2r1Ldeuyd+kpMBwZEMMRERFhxgxgyRLA2hr4+Wegc2fdz5WXV7p3qazxS56e2mEpMBCoVk33z61iGI4MiOGIiKiKW7ZMmo0GABs2AEOH6vf8QgDJyaV7lwoLtY+ztAQCAv4NS0FBQL167F16BIYjA2I4IiKqwrZtAwYMkAJMZCQwa5ZxPjcvT1ouQBWWYmKAW7dKH+fhUbp3yd7eODWaOIYjA2I4IiKqoo4dA7p1kwZiT5gArFghXy+NEMCNG9q9S6dOld271KKFdu+Sr2+V7F1iODIghiMioiooMREIDpam7vfpA2zfLg2aNiUPHpTuXUpJKX2cq6s02LtlS+myXMuWQOPGgI2NkQs2LoYjA2I4IiKqYtLSpB6XpCSgbVvg4EHzuVRVVu9SQUHp46ytgaZN/w1NquDk4mLceg2I4ciAGI6IiKqQnBwgNBQ4eRLw8wN++00a12Ou8vOB8+eB+Ph/H6dPA5mZZR9fp452YGrZ0mwXrGQ4MiCGIyKiKqKoCOjfH9i9G3Bzk4JRgwZyV6V/qrWXNANTfLy0ryzOztqX5Fq2BJo0AZRKIxWsG4YjA2I4IiKqAoQAXn0V+OILwNYWOHRImgVWldy7J/UqnT79b2A6d670oG9AGn/VpIl2aAoIAGrUMG7Nj8FwZEAMR0REVcCCBcBbb0mXj7Zvl3qQSBqvdOGC9iW5+HgpSJXFx6f0OKZ69QALC2NVrMZwZEAMR0REldzXXwPh4dL28uVARIS89Zg61bICD1+WS0oq+3hHR+1Lci1bSoPBbW0NWibDkQExHBERVWK//AL07CmNN5o5E1i4UO6KzFdmJvDnn9qB6ezZsmfLWVoCjRppB6bOnaX9esJwZEAMR0REldTp00BICJCdDQweLN0aRIbLP5VaYSGQkKB9SS4uTlo/SpOjI5CRodf2r8jvbxNbwYqIiEgGN24AvXpJwahTJyAqisHIEKytgebNpcfLL0v7hJAWq9TsYbKxkbX9GY6IiKhqy8iQLqXduiXNuNq50+SnpVcqCgXg7S09XnhB7moAAIzFRERUdeXnA//3f9IU9Zo1gb17K9Wq0KQbhiMiIqqaSkqA0aOlNYwcHIA9e4BnnpG7KjIBDEdERFQ1zZkjDbq2sgK2bZNmSBGB4YiIiKqilSuBDz+Utr/8EujRQ956yKQwHBERUdWyaxcwaZK0/e67/y74SPQPhiMiIqo6jh+X1jAqKQHGjJFuEUL0EIYjIiKqGi5fBvr0AfLypKn7K1dK08iJHsJwREREld+dO1IgunMHaN0a2LxZGohNVAaGIyIiqtxyc4G+faWeo7p1gd27pan7RI/AcERERJVXcTEwdCjw+++Aq6u0yKOXl9xVkYljOCIiospJCGDyZOCHH6TbgezaJd35negJGI6IiKhyWrwYWLFCGnT97bdAhw5yV0RmguGIiIgqn40bgZkzpe2lS4GXXpK3HjIrDEdERFS5HD4MjBghbU+dCkyZImMxZI4YjoiIqPI4dw7o3x8oKJB6ixYvlrsiMkMMR0REVDncuiWtZZSZKY0v+uYbwIK/5qji+F8NERGZv6wsoFcv4MYNwN9fmqFmayt3VWSmGI6IiMi8FRZKl9BOnwY8PaW1jKpXl7sqMmMMR0REZL6EAMaOBQ4cAOztpdWv69WTuyoycwxHRERkvubNA9avBywtpfultWkjd0VUCTAcERGRefryS+C996TtVaukMUdEesBwRERE5mfvXmD8eGn77beBMWPkrYcqFYYjIiIyL7GxwIAB0k1lw8OB+fPlrogqGYYjIiIyH0lJQO/eQE4O0L078MUX0r3TiPSI4YiIiMzD3bvSIo9paUBAALB1K2BtLXdVVAkxHBERkel78ADo2xdITAR8fIA9ewAnJ7mrokqK4YiIiEybEMArrwDHjgHOztJg7Fq15K6KKjGzCUcLFixAcHAwqlWrBhcXl1Kvnz59GkOGDIGPjw/s7OzQuHFjLFu2rNRxhw8fRuvWraFUKlG/fn1ERUUZvngiItLd/v3Ali2AjQ2wcyfQtKncFVElZzbhqKCgAAMGDMCECRPKfD02NhYeHh749ttvce7cOcyZMwezZ8/G8uXL1cckJSWhd+/e6Ny5M+Lj4zFlyhSMGTMGP//8s7G+DSIiqqjPPpO+TpgAhIbKWgpVDQohhJC7iIqIiorClClTkJGR8cRjIyIicOHCBRw8eBAA8Oabb2L37t04e/as+pjBgwcjIyMD+/btK9fnZ2VlwdnZGZmZmXDi9W4iIsO6cgVo0EC6tHbxorRNpIOK/P42m54jXWRmZqK6xs0HY2Ji0K1bN61jwsLCEBMTY+zSiIioPFaskIJRz54MRmQ0VnIXYCi//fYbNm3ahN27d6v3paamwtPTU+s4T09PZGVlIS8vD3Z2dqXOk5+fj/z8fPXzrKwswxVNRET/un8fWLtW2n79dXlroSpF1p6jWbNmQaFQPPaRkJBQ4fOePXsW/fr1w7x589CjR4+nqjEyMhLOzs7qh4+Pz1Odj4iIyumbb4CsLKnH6Cl/lhNVhKw9R9OnT8eIESMee4yvr2+Fznn+/Hl07doV48aNw1tvvaX1mpeXF9LS0rT2paWlwcnJqcxeIwCYPXs2pk2bpn6elZXFgEREZGhCAKoJNZMmARaVehQImRhZw5G7uzvc3d31dr5z586hS5cuCA8Px4IFC0q9HhQUhD179mjtO3DgAIKCgh55TqVSCaVSqbcaiYioHA4eBM6fBxwcgCf8EU2kb2Yz5ig5ORl3795FcnIyiouLER8fDwCoX78+HBwccPbsWXTp0gVhYWGYNm0aUlNTAQCWlpbqADZ+/HgsX74cM2fOxKhRo3Dw4EFs3rxZa1wSERGZANX0/fBwroRNRmc2U/lHjBiB9evXl9p/6NAhhIaG4p133sH8Mu7MXKdOHVy7dk39/PDhw5g6dSrOnz8Pb29vvP3220+8tKeJU/mJiAwsKQnw85MurV24ADRqJHdFVAlU5Pe32YQjU8FwRERkYG+8ASxeLA3C5iK9pCdc54iIiMxTbu6/0/dfe03eWqjKYjgiIiLTsWEDcO8e4OsrLfxIJAOGIyIiMg1CAJ9+Km1PmgRYWspbD1VZDEdERGQa/vc/4OxZoFo1YORIuauhKozhiIiITINq+v4rrwAuLrKWQlUbwxEREckvORnYuVPanjRJ1lKIGI6IiEh+K1cCJSVAly5A06ZyV0NVHMMRERHJKy8PWLNG2n79dXlrIQLDERERyW3jRuDuXaBuXeCFF+SuhojhiIiIZCTEvwOxJ07k9H0yCQxHREQkn2PHgPh4wM4OGD1a7mqIADAcERGRnFSLPg4fDlSvLm8tRP9gOCIiInncvAls3y5t8z5qZEIYjoiISB6rVgHFxUCnTkDz5nJXQ6TGcERERMb34MG/0/fZa0QmhuGIiIiMb/Nm4M4dwMcH6NdP7mqItDAcERGRcQnx70DsiRMBKyt56yF6CMMREREZ1++/A7GxgFIJjBkjdzVEpTAcERGRcakWfRw6FHBzk7cWojIwHBERkfHcugVs2SJtcyA2mSiGIyIiMp7Vq4GiIqBDB6BVK7mrISoTwxERERlHQYEUjgD2GpFJYzgiIiLj2LIFSEsDatcG/vMfuasheiSGIyIiMg7VQOzx4wFra3lrIXoMhiMiIjK8P/4Ajh8HbGyAcePkrobosRiOiIjI8FS9RoMHAx4e8tZC9AQMR0REZFhpacCmTdI2B2KTGWA4IiIiw1qzBigsBJ57DggMlLsaoidiOCIiIsMpLARWrpS22WtEZoLhiIiIDGfbNuCvvwAvL+Cll+SuhqhcGI6IiMhwNKfv29jIWwtROTEcERGRYZw6Bfz2m7Sm0auvyl0NUbkxHBERkWGoeo0GDJAuqxGZCYYjIiLSvzt3gI0bpW0OxCYzw3BERET698UXQH4+8OyzQLt2cldDVCEMR0REpF9FRdrT9xUKeeshqiCGIyIi0q+dO4GbN6XbhAwcKHc1RBXGcERERPqlGog9bhygVMpbC5EOGI6IiEh/Tp8GjhwBrKyktY2IzBDDERER6Y+q1+jFF4HateWthUhHDEdERKQff/8NbNggbXP6PpkxhiMiItKPtWuBBw+AVq2A4GC5qyHSGcMRERE9vaIiYMUKaZvT98nMMRwREdHT+/FHIDkZcHMDhgyRuxqip8JwRERET081EHvsWMDWVt5aiJ4SwxERET2ds2eBQ4cAS0tgwgS5qyF6agxHRET0dJYvl7727w/4+MhaCpE+MBwREZHu7t0DvvlG2n79dXlrIdIThiMiItLdV18BublAixZASIjc1RDpBcMRERHppriY0/epUmI4IiIi3ezZAyQlAa6uwNChcldDpDcMR0REpJtPP5W+jhkDVKsmby1EesRwREREFXfhAvDLL4CFBTBxotzVEOkVwxEREVWcavp+375A3bqylkKkbwxHRERUMZmZwPr10vZrr8lbC5EBMBwREVHFREUBOTlA06ZA585yV0OkdwxHRERUfiUl/15S4/R9qqQYjoiIqPz27QMuXwZcXIDhw+WuhsggGI6IiKj8PvtM+jpqFGBvL28tRAbCcEREROVz8aLUc6RQABERcldDZDAMR0REVD6qsUa9ewO+vvLWQmRAZhOOFixYgODgYFSrVg0uLi6PPfbvv/+Gt7c3FAoFMjIytF47fPgwWrduDaVSifr16yMqKspgNRMRVRrZ2dIsNQB4/XVZSyEyNLMJRwUFBRgwYAAmTJjwxGNHjx6NFi1alNqflJSE3r17o3PnzoiPj8eUKVMwZswY/Pzzz4YomYio8li/XgpIjRoB3brJXQ2RQVnJXUB5zZ8/HwCe2NOzcuVKZGRkYO7cudi7d6/Wa6tWrUK9evWwZMkSAEDjxo0RHR2Njz/+GGFhYQapm4jI7GlO3580idP3qdIzm56j8jh//jzeffddfP3117CwKP2txcTEoNtDf/GEhYUhJibmkefMz89HVlaW1oOIqEr55RcgMRFwdAReeUXuaogMrtKEo/z8fAwZMgSLFi3CM888U+Yxqamp8PT01Nrn6emJrKws5OXllfmeyMhIODs7qx8+Pj56r52IyKR9+qn0ddQoKSARVXKyhqNZs2ZBoVA89pGQkFCuc82ePRuNGzfGcD0vSjZ79mxkZmaqHzdu3NDr+YmITNqVK8CePdI2p+9TFSHrmKPp06djxIgRjz3Gt5zTRQ8ePIgzZ85g69atAAAhBADAzc0Nc+bMwfz58+Hl5YW0tDSt96WlpcHJyQl2dnZlnlepVEKpVJarBiKiSmfFCkAIoGdPoEEDuashMgpZw5G7uzvc3d31cq5t27ZpXRo7ceIERo0ahaNHj8LPzw8AEBQUhD2qv4D+ceDAAQQFBemlBiKiSuX+feCrr6Tt116TtxYiIzKb2WrJycm4e/cukpOTUVxcjPj4eABA/fr14eDgoA5AKunp6QCkGWmqdZHGjx+P5cuXY+bMmRg1ahQOHjyIzZs3Y/fu3cb8VoiIzMM33wCZmVKPEWf0UhViNuFo7ty5WL9+vfp5q1atAACHDh1CaGhouc5Rr1497N69G1OnTsWyZcvg7e2NL7/8ktP4iYgeJoT29P0yZgATVVYKoRqcQ+WSlZUFZ2dnZGZmwsnJSe5yiIgM49dfpcUeHRyAlBSAP+/IzFXk9zf/FCAiotI++0z6Gh7OYERVDsMRERFpS0oCfvxR2p40Sd5aiGTAcERERNo+/1y6ZUiPHtK91IiqGIYjIiL6V24usHattM3p+1RFMRwREdG/NmwA7t0DfH2lhR+JqiCGIyIikgjx70DsiAjA0lLeeohkwnBERESS//0POHMGqFZNusksURXFcERERBJVr9ErrwD/3FmAqCpiOCIiIiA5Gdi5U9rm9H2q4hiOiIgIWLlSmr7fpQvQtKnc1RDJiuGIiKiqy8sDvvhC2ub0fSKGIyKiKm/jRuDvv4E6dYA+feSuhkh2DEdERFUZp+8TlaKXcJSVlYWdO3fiwoUL+jgdEREZy7lzQHw8YGsLjB4tdzVEJkGncDRw4EAsX74cAJCXl4fAwEAMHDgQLVq0wLZt2/RaIBERGVBMjPQ1OBioXl3eWohMhE7h6MiRIwgJCQEA7NixA0IIZGRk4NNPP8X777+v1wKJiMiAVOHouefkrYPIhOgUjjIzM1H9n78w9u3bhxdffBHVqlVD7969cenSJb0WSEREBvT779JXhiMiNZ3CkY+PD2JiYpCTk4N9+/ahR48eAIB79+7B1tZWrwUSEZGBZGQAqrGi7drJWgqRKbHS5U1TpkzBsGHD4ODggDp16iA0NBSAdLmtefPm+qyPiIgM5Y8/pK9+foCHh7y1EJkQncLRxIkT0bZtW9y4cQPdu3eHhYXUAeXr68sxR0RE5oLjjYjKpFM4AoDAwEAEBgZq7evdu/dTF0REREbC8UZEZSp3OJo2bVq5T7p06VKdiiEiIiMpKQGOH5e2g4LkrYXIxJQ7HMXFxWk9P3XqFIqKiuDv7w8AuHjxIiwtLdGmTRv9VkhERPp38SJw7560+GOLFnJXQ2RSyh2ODh06pN5eunQpHB0dsX79eri6ugKQZqqNHDlSvf4RERGZMNUltcBAwNpa3lqITIxOU/mXLFmCyMhIdTACAFdXV7z//vtYsmSJ3oojIiID4XgjokfSKRxlZWXhzp07pfbfuXMH2dnZT10UEREZmCoccbwRUSk6haP//Oc/GDlyJLZv346bN2/i5s2b2LZtG0aPHo3/+7//03eNRESkT9nZwJkz0jZ7johK0Wkq/6pVqzBjxgwMHToUhYWF0omsrDB69GgsWrRIrwUSEZGenTwpzVbz8QFq1ZK7GiKTU+FwVFxcjJMnT2LBggVYtGgRrly5AgDw8/ODvb293gskIiI94yU1oseqcDiytLREjx49cOHCBdSrVw8tOAWUiMi8cGVsosfSacxRs2bNcPXqVX3XQkREhiYEZ6oRPYFO4ej999/HjBkz8NNPP+Gvv/5CVlaW1oOIiExUUhJw5460tlGrVnJXQ2SSdBqQ3atXLwBA3759oVAo1PuFEFAoFCguLtZPdUREpF+qXqPWraXVsYmoFJ3CkeZq2UREZEY43ojoiXQKR506ddJ3HUREZAwcb0T0RDqFI5Xc3FwkJyejoKBAaz9nsBERmaC8PCA+XtpmOCJ6JJ3C0Z07dzBy5Ejs3bu3zNc55oiIyATFxgJFRYCXF1CnjtzVEJksnWarTZkyBRkZGTh+/Djs7Oywb98+rF+/Hg0aNMCuXbv0XSMREemD5iU1jck0RKRNp56jgwcP4ocffkBgYCAsLCxQp04ddO/eHU5OToiMjETv3r31XScRET0tjjciKhedeo5ycnLg4eEBAHB1dcWdO3cAAM2bN8epU6f0Vx0REekPbxtCVC46hSN/f38kJiYCAAICArB69WqkpKRg1apVqFmzpl4LJCIiPbhxA0hJASwtgTZt5K6GyKTpdFlt8uTJ+OuvvwAA8+bNw/PPP48NGzbAxsYGUVFR+qyPiIj0QdVr1KIFwJuEEz2WTuFo+PDh6u02bdrg+vXrSEhIwDPPPAM3Nze9FUdERHrC8UZE5abTZbWHbzpbrVo1tG7dmsGIiMhUcbwRUbnp1HNUv359eHt7o1OnTggNDUWnTp1Qv359fddGRET6UFAgrXEEsOeIqBx06jm6ceMGIiMjYWdnh48++ggNGzaEt7c3hg0bhi+//FLfNRIR0dOIjwfy84EaNQD+IUv0RAohhHjak1y6dAkLFizAhg0bUFJSUqlXyM7KyoKzszMyMzPh5OQkdzlERE/26afA5MlA797ATz/JXQ2RLCry+1uny2q5ubmIjo7G4cOHcfjwYcTFxaFRo0aYNGkSQkNDdTklEREZSkyM9JWX1IjKRadw5OLiAldXVwwbNgyzZs1CSEgIXF1d9V0bERHpA2eqEVWITuGoV69eiI6Oxvfff4/U1FSkpqYiNDQUDRs21Hd9RET0NFJTgWvXpHuptW0rdzVEZkGnAdk7d+5Eeno69u3bh6CgIOzfvx8hISGoXbs2hg0bpu8aiYhIV8ePS1+bNgU4TpKoXHTqOVJp3rw5ioqKUFBQgAcPHuDnn3/Gpk2bsGHDBn3VR0RET4PjjYgqTKeeo6VLl6Jv376oUaMG2rVrh40bN6Jhw4bYtm2b+ia0RERkAjjeiKjCdOo52rhxIzp16oRx48YhJCQEzs7O+q6LiIieVlERcOKEtM2VsYnKTadwdEL1PxsREZmuM2eA3FxprFGjRnJXQ2Q2dLqsBgBHjx7F8OHDERQUhJSUFADAN998g+joaL0VR0RET0F1Sa1dO8BC5x/3RFWOTv+3bNu2DWFhYbCzs0NcXBzy8/MBAJmZmfjggw/0WiAREemI442IdKJTOHr//fexatUqfPHFF7C2tlbvb9++PU6dOqW34oiI6CmowhHHGxFViE7hKDExER07diy139nZGRkZGU9bExERPa2//wYuXpS2ufgjUYXoFI68vLxw+fLlUvujo6Ph6+v71EUREdFTUi3+2LAhUKOGvLUQmRmdwtHYsWMxefJkHD9+HAqFArdu3cKGDRswffp0TJgwQd81AgAWLFiA4OBgVKtWDS4uLo88LioqCi1atICtrS08PDwQERGh9fqff/6JkJAQ2NrawsfHBx999JFB6iUikhUvqRHpTKep/LNmzUJJSQm6du2K3NxcdOzYEUqlEm+88QbGjBmj7xoBAAUFBRgwYACCgoKwdu3aMo9ZunQplixZgkWLFqFdu3bIycnBtWvX1K9nZWWhR48e6NatG1atWoUzZ85g1KhRcHFxwbhx4wxSNxGRLLgyNpHOFEIIoeubCwoKcPnyZdy/fx9NmjTB6tWrsWjRIqSmpuqzRi1RUVGYMmVKqbFN9+7dQ+3atfHjjz+ia9euZb535cqVmDNnDlJTU2FjYwNACno7d+5EQkJCuT4/KysLzs7OyMzMhBPvU0REpqi4GHB1BbKzgbg4oGVLuSsikl1Ffn9X6LJafn4+Zs+ejcDAQLRv3x579uxBkyZNcO7cOfj7+2PZsmWYOnXqUxWvqwMHDqCkpAQpKSlo3LgxvL29MXDgQNy4cUN9TExMDDp27KgORgAQFhaGxMRE3Lt3r8zz5ufnIysrS+tBRGTSEhKkYGRvDzRrJnc1RGanQuFo7ty5WLlyJerWrYukpCQMGDAA48aNw8cff4wlS5YgKSkJb775pqFqfayrV6+ipKQEH3zwAT755BNs3boVd+/eRffu3VFQUAAASE1Nhaenp9b7VM8f1dsVGRkJZ2dn9cPHx8ew3wgR0dNSjTd69lnA6qnuL05UJVUoHG3ZsgVff/01tm7div3796O4uBhFRUU4ffo0Bg8eDEtLywp9+KxZs6BQKB77KO/lrpKSEhQWFuLTTz9FWFgYnnvuOWzcuBGXLl3CoUOHKlSXptmzZyMzM1P90OyJIiIySRxvRPRUKvQnxc2bN9GmTRsAQLNmzaBUKjF16lQoFAqdPnz69OkYMWLEY48p79IANWvWBAA0adJEvc/d3R1ubm5ITk4GIC1BkJaWpvU+1XMvL68yz6tUKqFUKstVAxGRSeDK2ERPpULhqLi4WGu8jpWVFRwcHHT+cHd3d7i7u+v8fk3t27cHIC1Q6e3tDQC4e/cu0tPTUadOHQBAUFAQ5syZg8LCQvXK3gcOHIC/vz9cXV31UgcRkawyM4Hz56VthiMinVQoHAkhMGLECHVPyoMHDzB+/HjY29trHbd9+3b9VfiP5ORk3L17F8nJySguLkZ8fDwAoH79+nBwcEDDhg3Rr18/TJ48GWvWrIGTkxNmz56NRo0aoXPnzgCAoUOHYv78+Rg9ejTefPNNnD17FsuWLcPHH3+s93qJiGTxxx+AEEC9esBDYyyJqHwqFI7Cw8O1ng8fPlyvxTzO3LlzsX79evXzVq1aAQAOHTqE0NBQAMDXX3+NqVOnonfv3rCwsECnTp2wb98+dS+Rs7Mz9u/fj4iICLRp0wZubm6YO3cu1zgiosqDl9SIntpTrXNUFXGdIyIyab17A3v2AMuWAa+/Lnc1RCbDYOscERGRCROCtw0h0gOGIyKiyuLSJeDuXUCpBAIC5K6GyGwxHBERVRaqXqM2bQCNmcVEVDEMR0RElQUvqRHpBcMREVFlwZlqRHrBcEREVBnk5AB//iltMxwRPRWGIyKiyuDkSaC4GKhdG/jnLgFEpBuGIyKiyoDjjYj0huGIiKgyiImRvvKSGtFTYzgiIjJ3mos/MhwRPTWGIyIic3f9OpCWBlhbA61by10NkdljOCIiMneqXqOWLQE7O1lLIaoMGI6IiMwdxxsR6RXDERGRueN4IyK9YjgiIjJnDx4AcXHSNqfxE+kFwxERkTk7dQooLAQ8PIC6deWuhqhSYDgiIjJnmpfUFAp5ayGqJBiOiIjMGVfGJtI7hiMiInPGwdhEesdwRERkrlJSgBs3AAsLIDBQ7mqIKg2GIyIic6XqNWreHHBwkLcWokqE4YiIyFxxvBGRQTAcERGZK66MTWQQDEdEROaooACIjZW2GY6I9IrhiIjIHP35p7Q6tqsr0LCh3NUQVSoMR0RE5oiLPxIZDMMREZE54ngjIoNhOCIiMkdc/JHIYBiOiIjMze3bwNWr0uW0du3kroao0mE4IiIyN8ePS18bNwacneWthagSYjgiIjI3HG9EZFAMR0RE5oYrYxMZFMMREZE5KS4G/vhD2mbPEZFBMBwREZmTs2eBnBzA0VEac0REesdwRERkTlSX1Nq2BSwt5a2FqJJiOCIiMiccb0RkcAxHRETmhIs/EhkcwxERkbm4exdISJC2ufgjkcEwHBERmQvVLLUGDQA3N3lrIarEGI6IiMwFL6kRGQXDERGRueDK2ERGwXBERGQOSkr+vacawxGRQTEcERGZg8REIDMTsLMDWrSQuxqiSo3hiIjIHKjGGz37LGBlJW8tRJUcwxERkTngeCMio2E4IiIyB1wZm8hoGI6IiExddrZ0w1mAiz8SGQHDERGRqfvjD0AIoE4doGZNuashqvQYjoiITB0XfyQyKoYjIiJTx/FGREbFcEREZMqEYM8RkZExHBERmbIrV4D0dMDGBmjZUu5qiKoEhiMiIlOm6jVq0wZQKuWthaiKYDgiIjJlvKRGZHQMR0REpozhiMjoGI6IiExVbi5w+rS0zXBEZDQMR0REpio2FigqAmrVAnx85K6GqMpgOCIiMlWal9QUCnlrIapCGI6IiExVTIz0lZfUiIyK4YiIyBQJ8W844srYREZlNuFowYIFCA4ORrVq1eDi4lLmMSdOnEDXrl3h4uICV1dXhIWF4bRqMOM//vzzT4SEhMDW1hY+Pj746KOPjFA9EVEF3bgBpKYCVlZA69ZyV0NUpZhNOCooKMCAAQMwYcKEMl+/f/8+nn/+eTzzzDM4fvw4oqOj4ejoiLCwMBQWFgIAsrKy0KNHD9SpUwexsbFYtGgR3nnnHaxZs8aY3woR0ZOpxhsFBADVqslbC1EVYyV3AeU1f/58AEBUVFSZryckJODu3bt499134fPPrI558+ahRYsWuH79OurXr48NGzagoKAAX331FWxsbNC0aVPEx8dj6dKlGDdunLG+FSKiJ+N4IyLZmE3P0ZP4+/ujRo0aWLt2LQoKCpCXl4e1a9eicePGqFu3LgAgJiYGHTt2hI2Njfp9YWFhSExMxL1792SqnIioDKqeI443IjK6ShOOHB0dcfjwYXz77bews7ODg4MD9u3bh71798LKSuogS01Nhaenp9b7VM9TU1PLPG9+fj6ysrK0HkREBpWfD5w6JW2z54jI6GQNR7NmzYJCoXjsIyEhoVznysvLw+jRo9G+fXv8/vvvOHbsGJo1a4bevXsjLy9P5xojIyPh7OysfvhwITYiMrS4OKCgAHBzA3x95a6GqMqRdczR9OnTMWLEiMce41vOHwzfffcdrl27hpiYGFhYWKj3ubq64ocffsDgwYPh5eWFtLQ0rfepnnt5eZV53tmzZ2PatGnq51lZWQxIRGRYmpfUuPgjkdHJGo7c3d3h7u6ul3Pl5ubCwsICCo0fJKrnJSUlAICgoCDMmTMHhYWFsLa2BgAcOHAA/v7+cHV1LfO8SqUSSqVSLzUSEZULbzZLJCuzGXOUnJyM+Ph4JCcno7i4GPHx8YiPj8f9+/cBAN27d8e9e/cQERGBCxcu4Ny5cxg5ciSsrKzQuXNnAMDQoUNhY2OD0aNH49y5c9i0aROWLVum1TNERCQ7hiMiWZnNVP65c+di/fr16uetWrUCABw6dAihoaFo1KgRfvzxR8yfPx9BQUGwsLBAq1atsG/fPtSsWRMA4OzsjP379yMiIgJt2rSBm5sb5s6dy2n8RGQ6/voLuH4dsLAAnn1W7mqIqiSFEELIXYQ5ycrKgrOzMzIzM+Hk5CR3OURU2ezYAfzf/wEtWgAPrfBPRLqryO9vs7msRkRUJfCSGpHsGI6IiEwJV8Ymkh3DERGRqSgsBE6elLa5MjaRbBiOiIhMxZkzQF4e4OICNGwodzVEVRbDERGRqVCNN2rXTpqtRkSy4P99RESmguONiEwCwxERkanQvG0IEcmG4YiIyBSkpwOXL0vbbdvKWwtRFcdwRERkClS9Ro0aAY+41yMRGQfDERGRKeAlNSKTwXBERGQKuDI2kclgOCIikltxMfDHH9I2wxGR7BiOiIjkdv48kJ0NODgATZvKXQ1RlcdwREQkN9UltbZtAUtLeWshIoYjIiLZcbwRkUlhOCIikhvDEZFJYTgiIpJTRoY05ghgOCIyEQxHRERyUs1S8/MD3N3lrYWIADAcERHJi5fUiEwOwxERkZxiYqSvDEdEJoPhiIhILiUlwPHj0jZvG0JkMhiOiIjkcukScO8eYGsLtGghdzVE9A+GIyIiuajGGwUGAtbW8tZCRGoMR0REclGNN+IlNSKTwnBERCQXzlQjMkkMR0REcrh/HzhzRtpmOCIyKQxHRERyOHFCmq3m4wPUqiV3NUSkgeGIiEgOqktqHG9EZHIYjoiI5MDxRkQmi+GIiMjYhGA4IjJhDEdERMaWlATcvg3Y2ACtW8tdDRE9hOGIiMjYVL1GrVoBSqW8tRBRKQxHRETGxktqRCaN4YiIyNhUK2MzHBGZJIYjIiJjyssD4uOlbU7jJzJJDEdERMZ06hRQVAR4eQHPPCN3NURUBoYjIiJj0hxvpFDIWwsRlYnhiIjImFTjjXhJjchkMRwRERkTZ6oRmTyGIyIiY7l5E0hJASwtgTZt5K6GiB6B4YiIyFhUvUYtWgD29vLWQkSPxHBERGQsHG9EZBYYjoiIjIXjjYjMAsMREZExFBQAsbHSNsMRkUljOCIiMob4eCA/H6hRA6hfX+5qiOgxGI6IiIyBiz8SmQ2GIyIiY+B4IyKzwXBERGQMDEdEZoPhiIjI0NLSgKQk6XJa27ZyV0NET8BwRERkaKpeo6ZNAScneWshoidiOCIiMjReUiMyKwxHRESGxpWxicwKwxERkSEVFQEnTkjb7DkiMgsMR0REhnT2LJCbK401atRI7mqIqBwYjoiIDEk13qhdO8CCP3KJzAH/TyUiMiSONyIyOwxHRESGxJlqRGbHSu4CiIgqhYIC4OJFaYzRuXPS4+xZ4NIl6fV27eStj4jKjeGIiKgiioqAy5f/DT+qIHTxovRaWfr3B6pXN2qZRKQ7hiMiorIUF0u3/NDsBTp3DkhIkHqJyuLkBDRrJq2E3bTpv9uensatnYieCsMREVVtQgDJyaUvh124AOTllf0ee3ugSZPSQah2ben+aURk1swiHF27dg3vvfceDh48iNTUVNSqVQvDhw/HnDlzYGNjoz7uzz//REREBE6cOAF3d3e89tprmDlzpta5tmzZgrfffhvXrl1DgwYNsHDhQvTq1cvY3xIRGZsQwK1bpS+HnTsH3L9f9nuUSikEPdwTVKcOp+UTVWJmEY4SEhJQUlKC1atXo379+jh79izGjh2LnJwcLF68GACQlZWFHj16oFu3bli1ahXOnDmDUaNGwcXFBePGjQMA/PbbbxgyZAgiIyPxwgsv4LvvvkP//v1x6tQpNGvWTM5vkYj06fbtfwOQZhDKyCj7eGtrwN9fOwA1awb4+gKWlkYtnYjkpxBCCLmL0MWiRYuwcuVKXL16FQCwcuVKzJkzB6mpqerepFmzZmHnzp1ISEgAAAwaNAg5OTn46aef1Od57rnn0LJlS6xatapcn5uVlQVnZ2dkZmbCSZ931y4uBm7e1N/5iKoCIYAbN0oHofT0so+3tAQaNCjdE9SggRSQiKjSqsjvb7PoOSpLZmYmqmvM/oiJiUHHjh21LrOFhYVh4cKFuHfvHlxdXRETE4Np06ZpnScsLAw7d+585Ofk5+cjPz9f/TwrK0t/34SmO3eAunUNc26iqkahkHp9Hu4J8veXLpURET2GWYajy5cv47PPPlNfUgOA1NRU1KtXT+s4z39miKSmpsLV1RWpqanqfZrHpKamPvKzIiMjMX/+fD1W/xi2tsb5HKLKxMNDOwA1bQo0bgxUqyZ3ZURkpmQNR7NmzcLChQsfe8yFCxfQSONmjSkpKXj++ecxYMAAjB071tAlYvbs2Vq9TVlZWfDx8dH/B3l5PXpmDBERERmNrOFo+vTpGDFixGOP8fX1VW/funULnTt3RnBwMNasWaN1nJeXF9LS0rT2qZ57eXk99hjV62VRKpVQshueiIioypA1HLm7u8Pd3b1cx6akpKBz585o06YN1q1bB4uHptEGBQVhzpw5KCwshPU/AysPHDgAf39/uLq6qo/59ddfMWXKFPX7Dhw4gCDeEJKIiIj+YRYLdaSkpCA0NBTPPPMMFi9ejDt37iA1NVVrrNDQoUNhY2OD0aNH49y5c9i0aROWLVumdUls8uTJ2LdvH5YsWYKEhAS88847OHnyJCZNmiTHt0VEREQmyCwGZB84cACXL1/G5cuX4e3trfWaaiUCZ2dn7N+/HxEREWjTpg3c3Nwwd+5c9RpHABAcHIzvvvsOb731Fv773/+iQYMG2LlzJ9c4IiIiIjWzXedILgZb54iIiIgMpiK/v83ishoRERGRsTAcEREREWlgOCIiIiLSwHBEREREpIHhiIiIiEgDwxERERGRBoYjIiIiIg0MR0REREQaGI6IiIiINJjF7UNMiWpB8aysLJkrISIiovJS/d4uz41BGI4qKDs7GwDg4+MjcyVERERUUdnZ2XB2dn7sMby3WgWVlJTg1q1bcHR0hEKhkLscnWVlZcHHxwc3btzgPeL+wTbRxvbQxvYojW2ije2hzdTaQwiB7Oxs1KpVCxYWjx9VxJ6jCrKwsIC3t7fcZeiNk5OTSfxHa0rYJtrYHtrYHqWxTbSxPbSZUns8qcdIhQOyiYiIiDQwHBERERFpYDiqopRKJebNmwelUil3KSaDbaKN7aGN7VEa20Qb20ObObcHB2QTERERaWDPEREREZEGhiMiIiIiDQxHRERERBoYjoiIiIg0MBxVYitWrEDdunVha2uLdu3a4Y8//njksV988QVCQkLg6uoKV1dXdOvW7bHHm6uKtImm77//HgqFAv379zdsgUZW0fbIyMhAREQEatasCaVSiYYNG2LPnj1GqtbwKtoen3zyCfz9/WFnZwcfHx9MnToVDx48MFK1hnXkyBH06dMHtWrVgkKhwM6dO5/4nsOHD6N169ZQKpWoX78+oqKiDF6nsVS0PbZv347u3bvD3d0dTk5OCAoKws8//2ycYo1El/9GVI4dOwYrKyu0bNnSYPU9DYajSmrTpk2YNm0a5s2bh1OnTiEgIABhYWG4fft2mccfPnwYQ4YMwaFDhxATEwMfHx/06NEDKSkpRq7ccCraJirXrl3DjBkzEBISYqRKjaOi7VFQUIDu3bvj2rVr2Lp1KxITE/HFF1+gdu3aRq7cMCraHt999x1mzZqFefPm4cKFC1i7di02bdqE//73v0au3DBycnIQEBCAFStWlOv4pKQk9O7dG507d0Z8fDymTJmCMWPGVJpAUNH2OHLkCLp37449e/YgNjYWnTt3Rp8+fRAXF2fgSo2nom2ikpGRgVdeeQVdu3Y1UGV6IKhSatu2rYiIiFA/Ly4uFrVq1RKRkZHlen9RUZFwdHQU69evN1SJRqdLmxQVFYng4GDx5ZdfivDwcNGvXz8jVGocFW2PlStXCl9fX1FQUGCsEo2qou0REREhunTporVv2rRpon379gatUw4AxI4dOx57zMyZM0XTpk219g0aNEiEhYUZsDJ5lKc9ytKkSRMxf/58/RdkAirSJoMGDRJvvfWWmDdvnggICDBoXbpiz1ElVFBQgNjYWHTr1k29z8LCAt26dUNMTEy5zpGbm4vCwkJUr17dUGUala5t8u6778LDwwOjR482RplGo0t77Nq1C0FBQYiIiICnpyeaNWuGDz74AMXFxcYq22B0aY/g4GDExsaqL71dvXoVe/bsQa9evYxSs6mJiYnRaj8ACAsLK/fPnMqupKQE2dnZleZnqq7WrVuHq1evYt68eXKX8li88WwllJ6ejuLiYnh6emrt9/T0REJCQrnO8eabb6JWrVqlftiZK13aJDo6GmvXrkV8fLwRKjQuXdrj6tWrOHjwIIYNG4Y9e/bg8uXLmDhxIgoLC03+B92T6NIeQ4cORXp6Ojp06AAhBIqKijB+/PhKc1mtolJTU8tsv6ysLOTl5cHOzk6mykzD4sWLcf/+fQwcOFDuUmRz6dIlzJo1C0ePHoWVlWnHD/YcUSkffvghvv/+e+zYsQO2trZylyOL7OxsvPzyy/jiiy/g5uYmdzkmoaSkBB4eHlizZg3atGmDQYMGYc6cOVi1apXcpcni8OHD+OCDD/D555/j1KlT2L59O3bv3o333ntP7tLIxHz33XeYP38+Nm/eDA8PD7nLkUVxcTGGDh2K+fPno2HDhnKX80SmHd1IJ25ubrC0tERaWprW/rS0NHh5eT32vYsXL8aHH36IX375BS1atDBkmUZV0Ta5cuUKrl27hj59+qj3lZSUAACsrKyQmJgIPz8/wxZtQLr8N1KzZk1YW1vD0tJSva9x48ZITU1FQUEBbGxsDFqzIenSHm+//TZefvlljBkzBgDQvHlz5OTkYNy4cZgzZw4sLKrW355eXl5ltp+Tk1OV7jX6/vvvMWbMGGzZsqXS9MTrIjs7GydPnkRcXBwmTZoEQPqZKoSAlZUV9u/fjy5dushc5b+q1v+9VYSNjQ3atGmDX3/9Vb2vpKQEv/76K4KCgh75vo8++gjvvfce9u3bh8DAQGOUajQVbZNGjRrhzJkziI+PVz/69u2rnonj4+NjzPL1Tpf/Rtq3b4/Lly+rQyIAXLx4ETVr1jTrYATo1h65ubmlApAqOIoqeMvKoKAgrfYDgAMHDjz2Z05lt3HjRowcORIbN25E79695S5HVk5OTqV+po4fPx7+/v6Ij49Hu3bt5C5Rm8wDwslAvv/+e6FUKkVUVJQ4f/68GDdunHBxcRGpqalCCCFefvllMWvWLPXxH374obCxsRFbt24Vf/31l/qRnZ0t17egdxVtk4dVttlqFW2P5ORk4ejoKCZNmiQSExPFTz/9JDw8PMT7778v17egVxVtj3nz5glHR0exceNGcfXqVbF//37h5+cnBg4cKNe3oFfZ2dkiLi5OxMXFCQBi6dKlIi4uTly/fl0IIcSsWbPEyy+/rD7+6tWrolq1auKNN94QFy5cECtWrBCWlpZi3759cn0LelXR9tiwYYOwsrISK1as0PqZmpGRIde3oHcVbZOHmfJsNYajSuyzzz4TzzzzjLCxsRFt27YVv//+u/q1Tp06ifDwcPXzOnXqCAClHvPmzTN+4QZUkTZ5WGULR0JUvD1+++030a5dO6FUKoWvr69YsGCBKCoqMnLVhlOR9igsLBTvvPOO8PPzE7a2tsLHx0dMnDhR3Lt3z/iFG8ChQ4fK/JmgaoPw8HDRqVOnUu9p2bKlsLGxEb6+vmLdunVGr9tQKtoenTp1euzxlYEu/41oMuVwpBCiCvb/EhERET0CxxwRERERaWA4IiIiItLAcERERESkgeGIiIiISAPDEREREZEGhiMiIiIiDQxHRERERBoYjoio0rp27RoUCgXi4+MN9hkjRoxA//79DXZ+oqrkyJEj6NOnD2rVqgWFQoGdO3dW+BxCCCxevBgNGzaEUqlE7dq1sWDBggqdg+GIiEzWiBEjoFAoSj2ef/75cr3fx8cHf/31F5o1a2bgSolIH3JychAQEIAVK1bofI7Jkyfjyy+/xOLFi5GQkIBdu3ahbdu2FTqHlc6fTkRkBM8//zzWrVuntU+pVJbrvZaWlvDy8jJEWURkAD179kTPnj0f+Xp+fj7mzJmDjRs3IiMjA82aNcPChQsRGhoKALhw4QJWrlyJs2fPwt/fHwBQr169CtfBniMiMmlKpRJeXl5aD1dXVwCAQqHAypUr0bNnT9jZ2cHX1xdbt25Vv/fhy2r37t3DsGHD4O7uDjs7OzRo0EAreJ05cwZdunSBnZ0datSogXHjxuH+/fvq14uLizFt2jS4uLigRo0amDlzJh6+A1NJSQkiIyNRr1492NnZISAgQKumJ9VARI82adIkxMTE4Pvvv8eff/6JAQMG4Pnnn8elS5cAAD/++CN8fX3x008/oV69eqhbty7GjBmDu3fvVuhzGI6IyKy9/fbbePHFF3H69GkMGzYMgwcPxoULFx557Pnz57F37171X5hubm4ApO78sLAwuLq64sSJE9iyZQt++eUXTJo0Sf3+JUuWICoqCl999RWio6Nx9+5d7NixQ+szIiMj8fXXX2PVqlU4d+4cpk6diuHDh+N///vfE2sgokdLTk7GunXrsGXLFoSEhMDPzw8zZsxAhw4d1H9gXL16FdevX8eWLVvw9ddfIyoqCrGxsXjppZcq9mHy3veWiOjRwsPDhaWlpbC3t9d6LFiwQAghBAAxfvx4rfe0a9dOTJgwQQghRFJSkgAg4uLihBBC9OnTR4wcObLMz1qzZo1wdXUV9+/fV+/bvXu3sLCwEKmpqUIIIWrWrCk++ugj9euFhYXC29tb9OvXTwghxIMHD0S1atXEb7/9pnXu0aNHiyFDhjyxBiL6FwCxY8cO9fOffvpJACj188DKykoMHDhQCCHE2LFjBQCRmJiofl9sbKwAIBISEsr92RxzREQmrXPnzli5cqXWvurVq6u3g4KCtF4LCgp65Oy0CRMm4MUXX8SpU6fQo0cP9O/fH8HBwQCksQoBAQGwt7dXH9++fXuUlJQgMTERtra2+Ouvv9CuXTv161ZWVggMDFRfWrt8+TJyc3PRvXt3rc8tKChAq1atnlgDET3a/fv3YWlpidjYWFhaWmq95uDgAACoWbMmrKys0LBhQ/VrjRs3BiD1PKnGIT0JwxERmTR7e3vUr19fL+fq2bMnrl+/jj179uDAgQPo2rUrIiIisHjxYr2cXzU+affu3ahdu7bWa6pB5IaugaiyatWqFYqLi3H79m2EhISUeUz79u1RVFSEK1euwM/PDwBw8eJFAECdOnXK/Vkcc0REZu33338v9Vz1l2JZ3N3dER4ejm+//RaffPIJ1qxZA0D66/L06dPIyclRH3vs2DFYWFjA398fzs7OqFmzJo4fP65+vaioCLGxsernTZo0gVKpRHJyMurXr6/18PHxeWINRFXd/fv3ER8fr+79TUpKQnx8PJKTk9GwYUMMGzYMr7zyCrZv346kpCT88ccfiIyMxO7duwEA3bp1Q+vWrTFq1CjExcUhNjYWr776Krp3767Vm/Qk7DkiIpOWn5+P1NRUrX1WVlbqQcxbtmxBYGAgOnTogA0bNuCPP/7A2rVryzzX3Llz0aZNGzRt2hT5+fn46aef1EFq2LBhmDdvHsLDw/HOO+/gzp07eO211/Dyyy/D09MTgLR+yocffogGDRqgUaNGWLp0KTIyMtTnd3R0xIwZMzB16lSUlJSgQ4cOyMzMxLFjx+Dk5ITw8PDH1kBU1Z08eRKdO3dWP582bRoAIDw8HFFRUVi3bh3ef/99TJ8+HSkpKXBzc8Nzzz2HF154AQBgYWGBH3/8Ea+99ho6duwIe3t79OzZE0uWLKlYIfoaOEVEpG/h4eECQKmHv7+/EEIasLlixQrRvXt3oVQqRd26dcWmTZvU7394QPZ7770nGjduLOzs7ET16tVFv379xNWrV9XH//nnn6Jz587C1tZWVK9eXYwdO1ZkZ2erXy8sLBSTJ08WTk5OwsXFRUybNk288sor6gHZQghRUlIiPvnkE+Hv7y+sra2Fu7u7CAsLE//73//KVQMRyU8hxEOLdBARmQmFQoEdO3bw9h1EpFccc0RERESkgeGIiIiISAMHZBOR2eKoACIyBPYcEREREWlgOCIiIiLSwHBEREREpIHhiIiIiEgDwxERERGRBoYjIiIiIg0MR0REREQaGI6IiIiINDAcEREREWn4f7IcGZh5OhgNAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x11947bb20>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ckpt_path = 'expert'\n",
    "total_steps = 1500000\n",
    "\n",
    "reseed(seed) \n",
    "expert_callback = PPOCallback(save_path=ckpt_path, eval_env=real_vec_env_1)\n",
    "\n",
    "# TODO\n",
    "expert_model = PPO('MlpPolicy', real_vec_env_3, verbose=1, **hyperparameters)\n",
    "expert_model.learn(total_timesteps=total_steps, callback=expert_callback)\n",
    "# END TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5: Evaluate Expert (2 points)\n",
    "\n",
    "Initialize an expert PPOActor instance and evaluate the expert agent using the `evaluate_policy` function on the real environment. \n",
    "\n",
    "**Expected Reward**: Around -130 to -100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:01<00:00, 54.54it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-103.45999908447266"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: MODIFY\n",
    "expert = PPOActor(model=expert_model)\n",
    "evaluate_policy(expert, real_vec_env_1, num_episodes=100)\n",
    "# END TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:01<00:00, 53.03it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-101.72000122070312"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_policy(expert, real_vec_env_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hpVfp16qPAc5"
   },
   "source": [
    "### 1.6: [PROVIDED] Visualize Expert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 438
    },
    "id": "6g4RRIu1PAc5",
    "outputId": "52b1844d-9067-4a22-a658-14e205e90951"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video saved as expert.mp4\n"
     ]
    }
   ],
   "source": [
    "visualize(algorithm=expert, video_name='expert')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aA9VUmpXPAc5"
   },
   "source": [
    "## Part 2: Collect Data and Train World Model\n",
    "\n",
    "### Overview: \n",
    "Unlike in simulation, we can rarely obtain the full transition function of real world scenarios, and we emulate that property in this assignment here. \n",
    "\n",
    "Assuming we do not have the underlying logic to the MountainCar-v0, given that we have an expert agent in solving this particular problem, we take the following modeled based reinforcement learning approach to learn an RL agent that can be applied to the real scenario. \n",
    "\n",
    "In real life, we might not have such a trained expert, and human operating the robot remotely could be one source of expert data. \n",
    "\n",
    "1. Rollout a series of expert trajectories in the true environment (analogous to collecting a set of human demonstrations on the robot) \n",
    "2. Define and train a world model with the trajectory transitions as input data\n",
    "3. Define a new environment that applies the trained world model\n",
    "4. Learn an RL agent under the learned environment\n",
    "5. Evaluate this agent using the real environment\n",
    "\n",
    "### Instructions\n",
    "\n",
    "You will need to implement the following functions and classes \n",
    "- `data_collect`: a helper function that rolls out a policy on an environment, and returning a tuple of lists representing the transitions \n",
    "- `WorldModel` : a `torch.nn` module defining the architecture of the world. \n",
    "- `train_world_model` and `eval_world_model`: Training and evaluation loop of the world model\n",
    "\n",
    "Follow the instructions below to implement each of these components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ajJw4tvPPAc5"
   },
   "source": [
    "### 2.1: Collect Data\n",
    "\n",
    "#### data_collect function (6 points)\n",
    "**Instructions**: \n",
    "\n",
    "The `data_collect` function should rollout a policy actor on the environment for a total of `num_steps`, with a maximum trajectory length of `traj_max_length`, then returning 3 lists: `observations`, `actions`, `next_observations` such that for any transition $i \\leq$ num_steps: \n",
    "\n",
    "data_env with intiial state `observations[i]`, when stepped with `actions[i]`, yields a new state `next_observations[i]`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "ynngHBnZPAc5"
   },
   "outputs": [],
   "source": [
    "def data_collect(num_steps: int, traj_max_length: int, data_env: gym.Env, actor: PPOActor):\n",
    "    '''\n",
    "    Collects observation, action, next_observation triplet data for `num_trajectories`\n",
    "    each with a maximimum step count of `traj_max_length`\n",
    "\n",
    "    - num_steps: Number of total steps to collect data over, should also be the sum of trajectory lengths\n",
    "    - traj_max_length: Maximum length of each trajectory\n",
    "    - data_env: The environment to collect data under, NOT A VECENV\n",
    "\n",
    "    - actor: A function that takes a `data_env` observation as input and outputs an action admissible to `data_env`\n",
    "\n",
    "    Returns: (observations, actions, next_observations), each being a list\n",
    "    '''\n",
    "    \n",
    "    observations, actions, next_obs = [], [], []\n",
    "    \n",
    "    # TODO: \n",
    "    total_steps = 0\n",
    "    while total_steps < num_steps: \n",
    "        obs, _ = data_env.reset()\n",
    "        done = False\n",
    "        steps = 0\n",
    "\n",
    "        while not done and steps < traj_max_length: \n",
    "            action = actor.select_action(obs)\n",
    "            next_observation, _, done, _, _= data_env.step(action)\n",
    "\n",
    "            observations.append(obs)\n",
    "            actions.append(action)\n",
    "            next_obs.append(next_observation)\n",
    "\n",
    "            obs = next_observation\n",
    "            steps += 1\n",
    "            total_steps += 1\n",
    "\n",
    "    # END TODO\n",
    "    return observations, actions, next_obs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Provided] function that visualizes collected data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_collected_data(observations, next_obs): \n",
    "    '''\n",
    "        Takes the first 300 data points and generates a \n",
    "        plot of the observations and next_obs. \n",
    "    '''\n",
    "    print(f'Dataset Size: {len(observations)}')\n",
    "    plt.close()\n",
    "    plt.plot(np.arange(300), observations[:300], c='blue')\n",
    "    plt.plot(np.arange(300), next_obs[:300], c='red')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Data Collection (1 point) \n",
    "\n",
    "**Instruction**: \n",
    "Run data collection function on the real policy with expert policy trained in part 1. \n",
    "\n",
    "**Note**: the `data_collect` function requires the environment provided to be a regular gymnasium environment instead of a vectorized environment. Please make sure to not confuse it with `real_vec_env_1` defined in part 1.1. \n",
    "\n",
    "**Note**: Here is a list of currently created environments after running this following cell: \n",
    "- `real_vec_env_1` \n",
    "- `real_vec_env_3` \n",
    "- `real_env` \n",
    "\n",
    "Refer to function documentation for selecting which one to use when doing function calls. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 465
    },
    "id": "LcvLC7IatH1l",
    "outputId": "bf8c8ce4-4834-4098-c8e6-36c9065ecab1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Size: 100002\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "total_steps = 100000\n",
    "traj_max_length = 500\n",
    "\n",
    "real_env = gym.make('MountainCar-v0', render_mode='rgb_array')\n",
    "\n",
    "reseed(data_seed, env=real_env) \n",
    "\n",
    "# TODO: MODIFY to run data collect function to collect data\n",
    "observations, actions, next_obs = data_collect(total_steps, traj_max_length, real_env, expert)\n",
    "\n",
    "# END TODO \n",
    "\n",
    "visualize_collected_data(observations, next_obs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[PROVIDED]: Defining the torch dataset and dataloader used for training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lKLqI54LPAc5",
    "outputId": "b4e21497-68f5-4d30-b31e-800c14ae9b7e"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class WorldDataset(Dataset):\n",
    "    def __init__(self, obs, actions, next_obs):\n",
    "        self.obs = obs\n",
    "        self.actions = actions\n",
    "        self.next_obs = next_obs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.obs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'orig_obs': self.obs[idx],\n",
    "            'action': self.actions[idx],\n",
    "            'next_obs': self.next_obs[idx]\n",
    "        }\n",
    "\n",
    "split = len(observations) // 5\n",
    "\n",
    "val_data = WorldDataset(observations[:split], actions[:split], next_obs[:split])\n",
    "train_data = WorldDataset(observations[split:], actions[split:], next_obs[split:])\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=128)\n",
    "val_dataloader = DataLoader(val_data, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qEDyy3aaPAc5"
   },
   "source": [
    "### 2.2: Define World Model (3 points)\n",
    "\n",
    "The `WorldModel` class should define a neural network that takes a state-action pair and outputs a state in the state space. The network should have the following architecture. \n",
    "\n",
    "- Layer 1: a fully-connected layer with `inp_dim` input nodes and `hidden_dim_1` output nodes, followed by a ReLU activation function.\n",
    "- Layer 2: a fully-connected layer with `hidden_dim_1` input nodes and `hidden_dim_2` output nodes, followed by a ReLU activation function.\n",
    "- Output layer: a fully-connected layer with `hidden_dim_2` input nodes and `output_dim` output nodes. \n",
    "\n",
    "The `forward` function should take two inputs: `state` and `action`, concatenate them along the last dimension, and then pass it through the model architecture. For instance, if the state has shape `n * s`, and the action has shape $n \\times a$, then the input to the model should be `n * (s + a)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "IgJgF-_2PAc5"
   },
   "outputs": [],
   "source": [
    "class WorldModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim_1, hidden_dim_2, output_dim):\n",
    "        super(WorldModel, self).__init__()\n",
    "        self.input_dim = input_dim \n",
    "\n",
    "        # TODO: \n",
    "        self.linear1 = nn.Linear(input_dim, hidden_dim_1)\n",
    "        self.linear2 = nn.Linear(hidden_dim_1, hidden_dim_2)\n",
    "        self.linear3 = nn.Linear(hidden_dim_2, output_dim)\n",
    "        # END TODO  \n",
    "\n",
    "    def forward(self, state, action):\n",
    "        '''\n",
    "            Expected `state` to have shape n * s_dim \n",
    "            Expected `action` to have shape n * a_dim\n",
    "        '''\n",
    "        n, s_dim = state.shape \n",
    "        n_a, a_dim = action.shape \n",
    "        assert n == n_a\n",
    "        assert s_dim + a_dim == self.input_dim\n",
    "        \n",
    "        # TODO: MODIFY\n",
    "        x = torch.cat([state, action], dim=1)\n",
    "        x = self.linear1(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.linear3(x)\n",
    "        return x\n",
    "        # END TODO\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lHd3cSEiPAc5"
   },
   "source": [
    "### 2.3: Define Training and Validation Function for World Model (12 points, 6 each): \n",
    "\n",
    "The `train_world_model` function should train the provided model for one epoch, using the optimizer and criterion provided on the given train_dataloader. This function should iterate through each batch of the `train_dataloader` once, update the world model based on the loss calculated by criterion, then step the optimizer. \n",
    "\n",
    "The `eval_world_model` function is similar to the `train_world_model` function with iteration through the batches of the `eval_dataloader` and computes the loss using the given criterion. Note that no update to model should be made and gradients should not be calculated during the forward pass. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_world_model(model, optimizer, criterion, train_dataloader):\n",
    "\n",
    "    '''\n",
    "        This function should train the torch model `model` using the \n",
    "        optim `optimizer` and `criterion` as loss function, on one pass \n",
    "        of the `train_dataloader` \n",
    "\n",
    "        This is should train the model for on epoch, as in one pass through\n",
    "        the training data. \n",
    "\n",
    "        Returns: the mean criterion loss across each batch of the dataset. \n",
    "    '''\n",
    "    # TODO: \n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        state = batch['orig_obs']\n",
    "        action = batch['action']\n",
    "        next_state = batch['next_obs']\n",
    "        if action.dim() == 1:\n",
    "            action = action.unsqueeze(1)\n",
    "        pred_next_state = model(state, action)\n",
    "        loss = criterion(pred_next_state, next_state)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(train_dataloader)\n",
    "    # END TODO\n",
    "\n",
    "def eval_world_model(model, criterion, eval_dataloader):\n",
    "    '''\n",
    "        This function should evaluate the torch model `model` using \n",
    "        `criterion` as loss function, on one pass of the `eval_dataloader` \n",
    "\n",
    "        This is should evaluate the model on the validation dataset. \n",
    "\n",
    "        Take note that during evaluation, the model should not be updated \n",
    "        in any way and gradients should not be calculated. \n",
    "\n",
    "        Returns: the mean criterion loss across each batch of the dataset. \n",
    "\n",
    "    '''\n",
    "    # TODO:\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    for batch in eval_dataloader:\n",
    "        state = batch['orig_obs']\n",
    "        action = batch['action']\n",
    "        next_state = batch['next_obs']\n",
    "        if action.dim() == 1:\n",
    "            action = action.unsqueeze(1)\n",
    "        pred_next_state = model(state, action)\n",
    "        loss = criterion(pred_next_state, next_state)\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(eval_dataloader)\n",
    "    # END TODO: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4: Train the World Model (3 points)\n",
    "\n",
    "Train an instance of `WorldModel` for 50 epochs with the dataloader built in previous section, using Adam optimizer and MSE loss, with an lr of 0.0001. \n",
    "\n",
    "Provide a plot of training and evaluation losses with respect to training epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "OoJ814CmPAc5",
    "outputId": "a912ba14-65f0-497f-8c4c-c8ca73eca53a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0, train_loss=0.021047767267351192, val_loss=0.0007726046826562898\n",
      "epoch=1, train_loss=0.0002936486153702137, val_loss=0.0002153423167305411\n",
      "epoch=2, train_loss=0.00019926179705822568, val_loss=0.00018249918053454605\n",
      "epoch=3, train_loss=0.00016196288526463233, val_loss=0.00015036616711947728\n",
      "epoch=4, train_loss=0.00012311405803433235, val_loss=0.00011204796980454358\n",
      "epoch=5, train_loss=8.478180543040134e-05, val_loss=7.193273436053801e-05\n",
      "epoch=6, train_loss=5.0442568886464055e-05, val_loss=3.9977436100129424e-05\n",
      "epoch=7, train_loss=2.430040957277381e-05, val_loss=1.5783301944555982e-05\n",
      "epoch=8, train_loss=8.88699226331741e-06, val_loss=4.3521514991335855e-06\n",
      "epoch=9, train_loss=2.793913478426068e-06, val_loss=3.1808367334836413e-06\n",
      "epoch=10, train_loss=1.4407658771817453e-06, val_loss=4.555016364795436e-06\n",
      "epoch=11, train_loss=1.3175862493037751e-06, val_loss=6.576649810717088e-06\n",
      "epoch=12, train_loss=1.362883080699934e-06, val_loss=9.914906991505365e-06\n",
      "epoch=13, train_loss=1.5143460890036853e-06, val_loss=9.582212781071089e-06\n",
      "epoch=14, train_loss=1.572665292777298e-06, val_loss=8.144785485577593e-06\n",
      "epoch=15, train_loss=1.6279820699808555e-06, val_loss=7.616324538433734e-06\n",
      "epoch=16, train_loss=1.596638764277768e-06, val_loss=7.477904181292719e-06\n",
      "epoch=17, train_loss=1.62219317048265e-06, val_loss=8.070488136373298e-06\n",
      "epoch=18, train_loss=1.6367406145584243e-06, val_loss=8.521766964839313e-06\n",
      "epoch=19, train_loss=1.6440306114982204e-06, val_loss=8.721120905786725e-06\n",
      "epoch=20, train_loss=1.6458496158390544e-06, val_loss=8.699737698372504e-06\n",
      "epoch=21, train_loss=1.645675951476079e-06, val_loss=8.646627250550843e-06\n",
      "epoch=22, train_loss=1.6454003184190543e-06, val_loss=8.614756877690594e-06\n",
      "epoch=23, train_loss=1.6450968482953345e-06, val_loss=8.600028525558923e-06\n",
      "epoch=24, train_loss=1.6447826107023414e-06, val_loss=8.593356023472326e-06\n",
      "epoch=25, train_loss=1.6444679797002236e-06, val_loss=8.59066779826584e-06\n",
      "epoch=26, train_loss=1.6441555233220936e-06, val_loss=8.587907227679844e-06\n",
      "epoch=27, train_loss=1.6438197984173482e-06, val_loss=8.586809503780804e-06\n",
      "epoch=28, train_loss=1.6434872386286243e-06, val_loss=8.585489850140372e-06\n",
      "epoch=29, train_loss=1.6431574347468694e-06, val_loss=8.58412770079447e-06\n",
      "epoch=30, train_loss=1.6428266379213678e-06, val_loss=8.583831444481287e-06\n",
      "epoch=31, train_loss=1.6424835438485138e-06, val_loss=8.584235881423822e-06\n",
      "epoch=32, train_loss=1.6421932692071296e-06, val_loss=8.58302639684622e-06\n",
      "epoch=33, train_loss=1.6418363333985664e-06, val_loss=8.583309038255436e-06\n",
      "epoch=34, train_loss=1.6415300902966913e-06, val_loss=8.582926708696058e-06\n",
      "epoch=35, train_loss=1.641181178127389e-06, val_loss=8.583198329723215e-06\n",
      "epoch=36, train_loss=1.6408787172013645e-06, val_loss=8.582896502030864e-06\n",
      "epoch=37, train_loss=1.6405454948145137e-06, val_loss=8.58228643601193e-06\n",
      "epoch=38, train_loss=1.6402120345207023e-06, val_loss=8.581956143887069e-06\n",
      "epoch=39, train_loss=1.6399103133763607e-06, val_loss=8.582112170020343e-06\n",
      "epoch=40, train_loss=1.6395724733243674e-06, val_loss=8.582266697949366e-06\n",
      "epoch=41, train_loss=1.6392605362553628e-06, val_loss=8.581997873473593e-06\n",
      "epoch=42, train_loss=1.6389265009894616e-06, val_loss=8.582812756830423e-06\n",
      "epoch=43, train_loss=1.638620531707602e-06, val_loss=8.583213460934432e-06\n",
      "epoch=44, train_loss=1.6383093929889785e-06, val_loss=8.583211974316102e-06\n",
      "epoch=45, train_loss=1.6379812090992589e-06, val_loss=8.583715283325575e-06\n",
      "epoch=46, train_loss=1.6376761445902836e-06, val_loss=8.584248664313925e-06\n",
      "epoch=47, train_loss=1.6373711719297397e-06, val_loss=8.583990325095543e-06\n",
      "epoch=48, train_loss=1.637036089691603e-06, val_loss=8.584947852124193e-06\n",
      "epoch=49, train_loss=1.6367372252922757e-06, val_loss=8.585927678427796e-06\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "\n",
    "reseed(seed)\n",
    "\n",
    "world_model = world_model = WorldModel(input_dim=3, hidden_dim_1=16, hidden_dim_2=128, output_dim=2)\n",
    "lr = 0.0001\n",
    "optimizer = torch.optim.Adam(world_model.parameters(), lr=lr)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "\n",
    "# TODO\n",
    "train_losses, val_losses = [], []\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train_world_model(world_model, optimizer, criterion, train_dataloader)\n",
    "    val_loss = eval_world_model(world_model, criterion, val_dataloader)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "\n",
    "    print(f'{epoch=}, {train_loss=}, {val_loss=}')\n",
    "import matplotlib.pyplot as plt\n",
    "x_epochs = [x for x in range(50)]\n",
    "plt.plot(x_epochs, train_losses, label='training')\n",
    "plt.plot(x_epochs, val_losses, label='validation')\n",
    "plt.xlabel('Training Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# END TODO: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xn9hLKeqPAc6"
   },
   "source": [
    "### 2.5: [PROVIDED] Build Gym Environment with World Model\n",
    "\n",
    "The following `WorldModelEnv` class is largely defined for you to train your next PPO agent as the reinforcement learning component of MBRL. \n",
    "\n",
    "In this environment, the reward is calculated the same as the MountainCar-v0 gymnasium environment, with a -1 for each step that the car has not reached the goal. \n",
    "\n",
    "\n",
    "**To Initialize** a `WorldModelEnv` environment, a `world_model` (an instance of WorldModel in this case) should be passed in as argument, which will be used as the transition function in the `step()` function. \n",
    "\n",
    "This environment is registered with an id of **WorldModelMountainCar**, which can be initialized using `gym.make` or directly initializing it. \n",
    "\n",
    "\n",
    "**Run the following cell to define and register this environment** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "sVRWMZ-BPAc6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/cs4756_a5/lib/python3.10/site-packages/gymnasium/envs/registration.py:694: UserWarning: \u001b[33mWARN: Overriding environment WorldModelMountainCar already in registry.\u001b[0m\n",
      "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n"
     ]
    }
   ],
   "source": [
    "class WorldModelEnv(gym.Env):\n",
    "    def __init__(self, world_model: WorldModel, render_mode: str='rgb_array'):\n",
    "        super(WorldModelEnv, self).__init__()\n",
    "        self.world_model = world_model\n",
    "        self.corr_env = gym.make('MountainCar-v0', render_mode=render_mode).unwrapped\n",
    "\n",
    "        self.action_space = gym.spaces.Discrete(3)\n",
    "        self.observation_space = gym.spaces.Box(low=np.array([-1.2,  -0.07]), high=np.array([0.6, 0.07]), shape=(2,), dtype='float32')\n",
    "        self.metadata = {\n",
    "            'render_modes': ['human', 'rgb_array']\n",
    "        }\n",
    "        self.render_mode = 'rgb_array'\n",
    "\n",
    "        self.state = np.array([np.random.rand(1).item() * 0.2 - 0.6, 0])\n",
    "\n",
    "        self.min_action, self.max_action = -1.0, 1.0\n",
    "        self.goal_position = 0.45\n",
    "\n",
    "        self.step_count = 0\n",
    "\n",
    "        \n",
    "    def seed(self, seed=None):\n",
    "        pass\n",
    "\n",
    "\n",
    "    def reset(self, seed=None):\n",
    "        self.state = np.array([np.random.rand(1).item() * 0.2 - 0.6, 0])\n",
    "        self.step_count = 0\n",
    "        self.corr_env.reset()\n",
    "        return self.state, {}\n",
    "\n",
    "    def step(self, action):\n",
    "        with torch.no_grad():\n",
    "            state = torch.from_numpy(self.state).float().unsqueeze(0) \n",
    "            action = torch.from_numpy(np.array([action])).unsqueeze(0)\n",
    "            next_state = self.world_model(state, action)\n",
    "            next_state = np.array(next_state.squeeze(0))\n",
    "            self.state = np.clip(next_state, a_min=np.array([-1.2, -0.07]), a_max=np.array([0.6, 0.07]))\n",
    "        self.step_count += 1\n",
    "\n",
    "        terminated = bool(self.state[0] >= self.goal_position)\n",
    "\n",
    "        # truncate = False\n",
    "        truncate = bool(self.step_count > 2999)\n",
    "        reward = -1\n",
    "        return self.state, reward, terminated, truncate, {}\n",
    "\n",
    "    def render(self):\n",
    "        self.corr_env.state = (self.state[0], self.state[1])\n",
    "        returned = self.corr_env.render()\n",
    "        return returned\n",
    "\n",
    "\n",
    "gym.register(id='WorldModelMountainCar', entry_point=WorldModelEnv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HP3oVCNTPAc6"
   },
   "source": [
    "### 2.6: Visualize World Model with Trained Expert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 875
    },
    "id": "ndcsAZKuPAc6",
    "outputId": "5c331f2b-d250-43f1-9572-7f2b42d08ccf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/cs4756_a5/lib/python3.10/site-packages/gymnasium/envs/registration.py:788: UserWarning: \u001b[33mWARN: The environment is being initialised with render_mode='rgb_array' that is not in the possible render_modes ([]).\u001b[0m\n",
      "  logger.warn(\n",
      "/opt/anaconda3/envs/cs4756_a5/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:181: DeprecationWarning: \u001b[33mWARN: Current gymnasium version requires that `Env.reset` can be passed `options` to allow the environment initialisation to be passed additional information.\u001b[0m\n",
      "  logger.deprecation(\n",
      "/opt/anaconda3/envs/cs4756_a5/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:135: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method was expecting numpy array dtype to be float32, actual type: float64\u001b[0m\n",
      "  logger.warn(\n",
      "/opt/anaconda3/envs/cs4756_a5/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:159: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n",
      "/opt/anaconda3/envs/cs4756_a5/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:135: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method was expecting numpy array dtype to be float32, actual type: float64\u001b[0m\n",
      "  logger.warn(\n",
      "/opt/anaconda3/envs/cs4756_a5/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:159: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n",
      "/opt/anaconda3/envs/cs4756_a5/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:335: UserWarning: \u001b[33mWARN: No render fps was declared in the environment (env.metadata['render_fps'] is None or not defined), rendering may occur at inconsistent fps.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video saved as expert_trained_world.mp4\n"
     ]
    }
   ],
   "source": [
    "visualize(\n",
    "    env_name='WorldModelMountainCar',\n",
    "    algorithm=expert,\n",
    "    video_name='expert_trained_world',\n",
    "    env_args={\n",
    "        'world_model': world_model\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Train a PPO agent on the Learned World Mode\n",
    "\n",
    "### Overview \n",
    "\n",
    "Now that we have learned a model that simulates the transition function of the real environment, it's time to train an agent on this model. \n",
    "\n",
    "### Instruction \n",
    "\n",
    "In this part, you will learn, visualize, and evaluate a PPO policy on the learned world model, similar to what happened in Part 1, using functions defined in the Helper Function section, Part 1, and Part 2. \n",
    "\n",
    "**Follow instructions to complete each component**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UL5elpEUg7jv"
   },
   "source": [
    "### 3.1: Train New PPO on learned world environment (4 points)\n",
    "\n",
    "**TODO 1 Instruction**: Initialize a 3-vectorized and a 1-vectorized WorldModelMountainCar environment. \n",
    "\n",
    "**TODO 2 Instruction**: For this part, we will train a separate PPO policy using the learned model environment. This model should be trained with the world model learned in the previous part for 1500000 steps, under a 3-vectorized environment, using the same hyperparameters provided in Part 1. \n",
    "\n",
    "\n",
    "**Note**: Here is a list of created environments after running this following cell: \n",
    "- `real_vec_env_1` \n",
    "- `real_vec_env_3` \n",
    "- `real_env` \n",
    "- `world_vec_env_1` \n",
    "- `world_vec_env_3`\n",
    "\n",
    "Refer to function documentation for selecting which one to use when doing function calls. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "az0BzwAihAsJ",
    "outputId": "332e1149-5ed2-4405-8665-1b77a135b291"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/cs4756_a5/lib/python3.10/site-packages/gymnasium/envs/registration.py:788: UserWarning: \u001b[33mWARN: The environment is being initialised with render_mode='rgb_array' that is not in the possible render_modes ([]).\u001b[0m\n",
      "  logger.warn(\n",
      "/opt/anaconda3/envs/cs4756_a5/lib/python3.10/site-packages/stable_baselines3/ppo/ppo.py:155: UserWarning: You have specified a mini-batch size of 64, but because the `RolloutBuffer` is of size `n_steps * n_envs = 30000`, after every 468 untruncated mini-batches, there will be a truncated mini-batch of size 48\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=10000 and n_envs=3)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/cs4756_a5/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:181: DeprecationWarning: \u001b[33mWARN: Current gymnasium version requires that `Env.reset` can be passed `options` to allow the environment initialisation to be passed additional information.\u001b[0m\n",
      "  logger.deprecation(\n",
      "/opt/anaconda3/envs/cs4756_a5/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:135: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method was expecting numpy array dtype to be float32, actual type: float64\u001b[0m\n",
      "  logger.warn(\n",
      "/opt/anaconda3/envs/cs4756_a5/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:159: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n",
      "/opt/anaconda3/envs/cs4756_a5/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:135: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method was expecting numpy array dtype to be float32, actual type: float64\u001b[0m\n",
      "  logger.warn(\n",
      "/opt/anaconda3/envs/cs4756_a5/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:159: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.3     |\n",
      "|    ep_rew_mean     | -30.3    |\n",
      "| time/              |          |\n",
      "|    fps             | 7593     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 3        |\n",
      "|    total_timesteps | 30000    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 27.2        |\n",
      "|    ep_rew_mean          | -27.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3881        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 15          |\n",
      "|    total_timesteps      | 60000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020101797 |\n",
      "|    clip_fraction        | 0.29        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 0.00429     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.159       |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.00715    |\n",
      "|    value_loss           | 4.06        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 25.6      |\n",
      "|    ep_rew_mean          | -25.6     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 3315      |\n",
      "|    iterations           | 3         |\n",
      "|    time_elapsed         | 27        |\n",
      "|    total_timesteps      | 90000     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0318474 |\n",
      "|    clip_fraction        | 0.42      |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.01     |\n",
      "|    explained_variance   | 0.862     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.298     |\n",
      "|    n_updates            | 20        |\n",
      "|    policy_gradient_loss | -0.0211   |\n",
      "|    value_loss           | 0.718     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 173.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating self.num_timesteps=120000, mean_reward=-24.399999618530273=======\n",
      "model saved on eval reward: -24.399999618530273\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 23.7       |\n",
      "|    ep_rew_mean          | -23.7      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 3092       |\n",
      "|    iterations           | 4          |\n",
      "|    time_elapsed         | 38         |\n",
      "|    total_timesteps      | 120000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07301809 |\n",
      "|    clip_fraction        | 0.39       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.878     |\n",
      "|    explained_variance   | 0.981      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.296      |\n",
      "|    n_updates            | 30         |\n",
      "|    policy_gradient_loss | -0.0574    |\n",
      "|    value_loss           | 0.564      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 22.4       |\n",
      "|    ep_rew_mean          | -22.4      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 2980       |\n",
      "|    iterations           | 5          |\n",
      "|    time_elapsed         | 50         |\n",
      "|    total_timesteps      | 150000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04075901 |\n",
      "|    clip_fraction        | 0.418      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.706     |\n",
      "|    explained_variance   | 0.989      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0531     |\n",
      "|    n_updates            | 40         |\n",
      "|    policy_gradient_loss | -0.0645    |\n",
      "|    value_loss           | 0.367      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 21.2       |\n",
      "|    ep_rew_mean          | -21.2      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 2912       |\n",
      "|    iterations           | 6          |\n",
      "|    time_elapsed         | 61         |\n",
      "|    total_timesteps      | 180000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.10889906 |\n",
      "|    clip_fraction        | 0.24       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.478     |\n",
      "|    explained_variance   | 0.989      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0509     |\n",
      "|    n_updates            | 50         |\n",
      "|    policy_gradient_loss | -0.0506    |\n",
      "|    value_loss           | 0.189      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 20.9       |\n",
      "|    ep_rew_mean          | -20.9      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 2866       |\n",
      "|    iterations           | 7          |\n",
      "|    time_elapsed         | 73         |\n",
      "|    total_timesteps      | 210000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07245956 |\n",
      "|    clip_fraction        | 0.079      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.34      |\n",
      "|    explained_variance   | 0.994      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.00432    |\n",
      "|    n_updates            | 60         |\n",
      "|    policy_gradient_loss | -0.0259    |\n",
      "|    value_loss           | 0.0657     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 202.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating self.num_timesteps=240000, mean_reward=-20.75=======\n",
      "model saved on eval reward: -20.75\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 20.8        |\n",
      "|    ep_rew_mean          | -20.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2828        |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 84          |\n",
      "|    total_timesteps      | 240000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008888586 |\n",
      "|    clip_fraction        | 0.0598      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.279      |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.025       |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    value_loss           | 0.0503      |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 20.5        |\n",
      "|    ep_rew_mean          | -20.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2803        |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 96          |\n",
      "|    total_timesteps      | 270000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020896038 |\n",
      "|    clip_fraction        | 0.0447      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.212      |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0152      |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0078     |\n",
      "|    value_loss           | 0.0419      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 20.6         |\n",
      "|    ep_rew_mean          | -20.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2784         |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 107          |\n",
      "|    total_timesteps      | 300000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019454032 |\n",
      "|    clip_fraction        | 0.0222       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.18        |\n",
      "|    explained_variance   | 0.999        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0195       |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.00307     |\n",
      "|    value_loss           | 0.0352       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 20.6         |\n",
      "|    ep_rew_mean          | -20.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2769         |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 119          |\n",
      "|    total_timesteps      | 330000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014406544 |\n",
      "|    clip_fraction        | 0.0177       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.149       |\n",
      "|    explained_variance   | 0.999        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0185       |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -0.00251     |\n",
      "|    value_loss           | 0.0353       |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 209.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating self.num_timesteps=360000, mean_reward=-20.700000762939453=======\n",
      "model saved on eval reward: -20.700000762939453\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 20.6         |\n",
      "|    ep_rew_mean          | -20.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2753         |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 130          |\n",
      "|    total_timesteps      | 360000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012291528 |\n",
      "|    clip_fraction        | 0.0154       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.137       |\n",
      "|    explained_variance   | 0.999        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00866      |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.00221     |\n",
      "|    value_loss           | 0.0334       |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 20.6         |\n",
      "|    ep_rew_mean          | -20.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2734         |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 142          |\n",
      "|    total_timesteps      | 390000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008998297 |\n",
      "|    clip_fraction        | 0.0138       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.111       |\n",
      "|    explained_variance   | 0.999        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0188       |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.0016      |\n",
      "|    value_loss           | 0.0326       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 20.6         |\n",
      "|    ep_rew_mean          | -20.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2717         |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 154          |\n",
      "|    total_timesteps      | 420000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007462155 |\n",
      "|    clip_fraction        | 0.00902      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0999      |\n",
      "|    explained_variance   | 0.999        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00611      |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.000825    |\n",
      "|    value_loss           | 0.031        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 20.5         |\n",
      "|    ep_rew_mean          | -20.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2695         |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 166          |\n",
      "|    total_timesteps      | 450000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005026814 |\n",
      "|    clip_fraction        | 0.00903      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0807      |\n",
      "|    explained_variance   | 0.999        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0139       |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.00125     |\n",
      "|    value_loss           | 0.0317       |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 168.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating self.num_timesteps=480000, mean_reward=-20.600000381469727=======\n",
      "model saved on eval reward: -20.600000381469727\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 20.7          |\n",
      "|    ep_rew_mean          | -20.7         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 2680          |\n",
      "|    iterations           | 16            |\n",
      "|    time_elapsed         | 179           |\n",
      "|    total_timesteps      | 480000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00045781737 |\n",
      "|    clip_fraction        | 0.00814       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0641       |\n",
      "|    explained_variance   | 0.999         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.000712      |\n",
      "|    n_updates            | 150           |\n",
      "|    policy_gradient_loss | -0.000815     |\n",
      "|    value_loss           | 0.0315        |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 20.6         |\n",
      "|    ep_rew_mean          | -20.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2662         |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 191          |\n",
      "|    total_timesteps      | 510000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002779205 |\n",
      "|    clip_fraction        | 0.00382      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0553      |\n",
      "|    explained_variance   | 0.999        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0208       |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.000294    |\n",
      "|    value_loss           | 0.0325       |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 20.5          |\n",
      "|    ep_rew_mean          | -20.5         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 2655          |\n",
      "|    iterations           | 18            |\n",
      "|    time_elapsed         | 203           |\n",
      "|    total_timesteps      | 540000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00030070372 |\n",
      "|    clip_fraction        | 0.00453       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0505       |\n",
      "|    explained_variance   | 0.999         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.0192        |\n",
      "|    n_updates            | 170           |\n",
      "|    policy_gradient_loss | -0.000203     |\n",
      "|    value_loss           | 0.0313        |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 20.7         |\n",
      "|    ep_rew_mean          | -20.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2652         |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 214          |\n",
      "|    total_timesteps      | 570000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003406732 |\n",
      "|    clip_fraction        | 0.00559      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0422      |\n",
      "|    explained_variance   | 0.999        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0253       |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.000722    |\n",
      "|    value_loss           | 0.0324       |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 208.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating self.num_timesteps=600000, mean_reward=-20.700000762939453=======\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 20.6          |\n",
      "|    ep_rew_mean          | -20.6         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 2649          |\n",
      "|    iterations           | 20            |\n",
      "|    time_elapsed         | 226           |\n",
      "|    total_timesteps      | 600000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00015766433 |\n",
      "|    clip_fraction        | 0.0024        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0385       |\n",
      "|    explained_variance   | 0.999         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.0163        |\n",
      "|    n_updates            | 190           |\n",
      "|    policy_gradient_loss | -9.65e-05     |\n",
      "|    value_loss           | 0.0311        |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 20.7          |\n",
      "|    ep_rew_mean          | -20.7         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 2645          |\n",
      "|    iterations           | 21            |\n",
      "|    time_elapsed         | 238           |\n",
      "|    total_timesteps      | 630000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00018095592 |\n",
      "|    clip_fraction        | 0.0024        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0373       |\n",
      "|    explained_variance   | 0.999         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.00769       |\n",
      "|    n_updates            | 200           |\n",
      "|    policy_gradient_loss | -0.000231     |\n",
      "|    value_loss           | 0.0315        |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 20.6          |\n",
      "|    ep_rew_mean          | -20.6         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 2634          |\n",
      "|    iterations           | 22            |\n",
      "|    time_elapsed         | 250           |\n",
      "|    total_timesteps      | 660000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00015441356 |\n",
      "|    clip_fraction        | 0.00182       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0322       |\n",
      "|    explained_variance   | 0.999         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.0168        |\n",
      "|    n_updates            | 210           |\n",
      "|    policy_gradient_loss | -8.29e-05     |\n",
      "|    value_loss           | 0.0322        |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 20.6          |\n",
      "|    ep_rew_mean          | -20.6         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 2624          |\n",
      "|    iterations           | 23            |\n",
      "|    time_elapsed         | 262           |\n",
      "|    total_timesteps      | 690000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00032600207 |\n",
      "|    clip_fraction        | 0.00253       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0299       |\n",
      "|    explained_variance   | 0.999         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.013         |\n",
      "|    n_updates            | 220           |\n",
      "|    policy_gradient_loss | -0.000247     |\n",
      "|    value_loss           | 0.0307        |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 201.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating self.num_timesteps=720000, mean_reward=-20.649999618530273=======\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 20.6           |\n",
      "|    ep_rew_mean          | -20.6          |\n",
      "| time/                   |                |\n",
      "|    fps                  | 2616           |\n",
      "|    iterations           | 24             |\n",
      "|    time_elapsed         | 275            |\n",
      "|    total_timesteps      | 720000         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.000121658384 |\n",
      "|    clip_fraction        | 0.00172        |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.0275        |\n",
      "|    explained_variance   | 0.999          |\n",
      "|    learning_rate        | 0.0003         |\n",
      "|    loss                 | 0.0169         |\n",
      "|    n_updates            | 230            |\n",
      "|    policy_gradient_loss | -0.000147      |\n",
      "|    value_loss           | 0.0305         |\n",
      "--------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 20.5           |\n",
      "|    ep_rew_mean          | -20.5          |\n",
      "| time/                   |                |\n",
      "|    fps                  | 2608           |\n",
      "|    iterations           | 25             |\n",
      "|    time_elapsed         | 287            |\n",
      "|    total_timesteps      | 750000         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.000110507965 |\n",
      "|    clip_fraction        | 0.00163        |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.0264        |\n",
      "|    explained_variance   | 0.999          |\n",
      "|    learning_rate        | 0.0003         |\n",
      "|    loss                 | 0.0143         |\n",
      "|    n_updates            | 240            |\n",
      "|    policy_gradient_loss | -3.46e-05      |\n",
      "|    value_loss           | 0.0328         |\n",
      "--------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 20.7         |\n",
      "|    ep_rew_mean          | -20.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2603         |\n",
      "|    iterations           | 26           |\n",
      "|    time_elapsed         | 299          |\n",
      "|    total_timesteps      | 780000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.017212e-05 |\n",
      "|    clip_fraction        | 0.0021       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0207      |\n",
      "|    explained_variance   | 0.999        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0114       |\n",
      "|    n_updates            | 250          |\n",
      "|    policy_gradient_loss | -0.000201    |\n",
      "|    value_loss           | 0.0301       |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 20.6          |\n",
      "|    ep_rew_mean          | -20.6         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 2597          |\n",
      "|    iterations           | 27            |\n",
      "|    time_elapsed         | 311           |\n",
      "|    total_timesteps      | 810000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00012785791 |\n",
      "|    clip_fraction        | 0.00105       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0193       |\n",
      "|    explained_variance   | 0.999         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.0103        |\n",
      "|    n_updates            | 260           |\n",
      "|    policy_gradient_loss | -3.53e-05     |\n",
      "|    value_loss           | 0.0306        |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 198.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating self.num_timesteps=840000, mean_reward=-20.5=======\n",
      "model saved on eval reward: -20.5\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 20.7         |\n",
      "|    ep_rew_mean          | -20.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2592         |\n",
      "|    iterations           | 28           |\n",
      "|    time_elapsed         | 324          |\n",
      "|    total_timesteps      | 840000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065377597 |\n",
      "|    clip_fraction        | 0.052        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.108       |\n",
      "|    explained_variance   | 0.999        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0042      |\n",
      "|    n_updates            | 270          |\n",
      "|    policy_gradient_loss | -0.00726     |\n",
      "|    value_loss           | 0.0327       |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 20.7         |\n",
      "|    ep_rew_mean          | -20.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2586         |\n",
      "|    iterations           | 29           |\n",
      "|    time_elapsed         | 336          |\n",
      "|    total_timesteps      | 870000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021873717 |\n",
      "|    clip_fraction        | 0.0448       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.154       |\n",
      "|    explained_variance   | 0.999        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0062       |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | -0.00629     |\n",
      "|    value_loss           | 0.0415       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 20.6        |\n",
      "|    ep_rew_mean          | -20.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2582        |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 348         |\n",
      "|    total_timesteps      | 900000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001803043 |\n",
      "|    clip_fraction        | 0.0346      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.131      |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0136      |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.00574    |\n",
      "|    value_loss           | 0.0381      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 20.6         |\n",
      "|    ep_rew_mean          | -20.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2574         |\n",
      "|    iterations           | 31           |\n",
      "|    time_elapsed         | 361          |\n",
      "|    total_timesteps      | 930000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012758279 |\n",
      "|    clip_fraction        | 0.0276       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.113       |\n",
      "|    explained_variance   | 0.999        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0112       |\n",
      "|    n_updates            | 300          |\n",
      "|    policy_gradient_loss | -0.00412     |\n",
      "|    value_loss           | 0.0343       |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 202.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating self.num_timesteps=960000, mean_reward=-20.799999237060547=======\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 20.7          |\n",
      "|    ep_rew_mean          | -20.7         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 2568          |\n",
      "|    iterations           | 32            |\n",
      "|    time_elapsed         | 373           |\n",
      "|    total_timesteps      | 960000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00091218005 |\n",
      "|    clip_fraction        | 0.02          |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0977       |\n",
      "|    explained_variance   | 0.999         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.0244        |\n",
      "|    n_updates            | 310           |\n",
      "|    policy_gradient_loss | -0.00363      |\n",
      "|    value_loss           | 0.0353        |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 20.7          |\n",
      "|    ep_rew_mean          | -20.7         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 2553          |\n",
      "|    iterations           | 33            |\n",
      "|    time_elapsed         | 387           |\n",
      "|    total_timesteps      | 990000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00081674603 |\n",
      "|    clip_fraction        | 0.0164        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0816       |\n",
      "|    explained_variance   | 0.999         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.00992       |\n",
      "|    n_updates            | 320           |\n",
      "|    policy_gradient_loss | -0.00209      |\n",
      "|    value_loss           | 0.0334        |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 20.6         |\n",
      "|    ep_rew_mean          | -20.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2552         |\n",
      "|    iterations           | 34           |\n",
      "|    time_elapsed         | 399          |\n",
      "|    total_timesteps      | 1020000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007437663 |\n",
      "|    clip_fraction        | 0.0121       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.064       |\n",
      "|    explained_variance   | 0.999        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0128       |\n",
      "|    n_updates            | 330          |\n",
      "|    policy_gradient_loss | -0.00154     |\n",
      "|    value_loss           | 0.0303       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 20.6         |\n",
      "|    ep_rew_mean          | -20.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2547         |\n",
      "|    iterations           | 35           |\n",
      "|    time_elapsed         | 412          |\n",
      "|    total_timesteps      | 1050000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005276665 |\n",
      "|    clip_fraction        | 0.0117       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0524      |\n",
      "|    explained_variance   | 0.999        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0122       |\n",
      "|    n_updates            | 340          |\n",
      "|    policy_gradient_loss | -0.00181     |\n",
      "|    value_loss           | 0.0315       |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 207.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating self.num_timesteps=1080000, mean_reward=-20.600000381469727=======\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 20.6          |\n",
      "|    ep_rew_mean          | -20.6         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 2537          |\n",
      "|    iterations           | 36            |\n",
      "|    time_elapsed         | 425           |\n",
      "|    total_timesteps      | 1080000       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00035153155 |\n",
      "|    clip_fraction        | 0.00745       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0446       |\n",
      "|    explained_variance   | 0.999         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.012         |\n",
      "|    n_updates            | 350           |\n",
      "|    policy_gradient_loss | -0.00104      |\n",
      "|    value_loss           | 0.0324        |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 20.5        |\n",
      "|    ep_rew_mean          | -20.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2538        |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 437         |\n",
      "|    total_timesteps      | 1110000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000390941 |\n",
      "|    clip_fraction        | 0.0064      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0335     |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.022       |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.00063    |\n",
      "|    value_loss           | 0.0308      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 20.7         |\n",
      "|    ep_rew_mean          | -20.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2539         |\n",
      "|    iterations           | 38           |\n",
      "|    time_elapsed         | 448          |\n",
      "|    total_timesteps      | 1140000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007987928 |\n",
      "|    clip_fraction        | 0.00279      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0231      |\n",
      "|    explained_variance   | 0.999        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0114       |\n",
      "|    n_updates            | 370          |\n",
      "|    policy_gradient_loss | -0.000507    |\n",
      "|    value_loss           | 0.0289       |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 20.6          |\n",
      "|    ep_rew_mean          | -20.6         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 2535          |\n",
      "|    iterations           | 39            |\n",
      "|    time_elapsed         | 461           |\n",
      "|    total_timesteps      | 1170000       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00010622086 |\n",
      "|    clip_fraction        | 0.00191       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0187       |\n",
      "|    explained_variance   | 0.999         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.0143        |\n",
      "|    n_updates            | 380           |\n",
      "|    policy_gradient_loss | -0.000212     |\n",
      "|    value_loss           | 0.0297        |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 200.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating self.num_timesteps=1200000, mean_reward=-20.600000381469727=======\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 20.6         |\n",
      "|    ep_rew_mean          | -20.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2532         |\n",
      "|    iterations           | 40           |\n",
      "|    time_elapsed         | 473          |\n",
      "|    total_timesteps      | 1200000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.099072e-05 |\n",
      "|    clip_fraction        | 0.00197      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0168      |\n",
      "|    explained_variance   | 0.999        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00945      |\n",
      "|    n_updates            | 390          |\n",
      "|    policy_gradient_loss | -0.000171    |\n",
      "|    value_loss           | 0.0287       |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 20.5         |\n",
      "|    ep_rew_mean          | -20.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2530         |\n",
      "|    iterations           | 41           |\n",
      "|    time_elapsed         | 486          |\n",
      "|    total_timesteps      | 1230000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.368962e-05 |\n",
      "|    clip_fraction        | 0.00183      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0143      |\n",
      "|    explained_variance   | 0.999        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0125       |\n",
      "|    n_updates            | 400          |\n",
      "|    policy_gradient_loss | -0.000165    |\n",
      "|    value_loss           | 0.029        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 20.7         |\n",
      "|    ep_rew_mean          | -20.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2528         |\n",
      "|    iterations           | 42           |\n",
      "|    time_elapsed         | 498          |\n",
      "|    total_timesteps      | 1260000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.602647e-05 |\n",
      "|    clip_fraction        | 0.00139      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0115      |\n",
      "|    explained_variance   | 0.999        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00877      |\n",
      "|    n_updates            | 410          |\n",
      "|    policy_gradient_loss | -0.000123    |\n",
      "|    value_loss           | 0.0286       |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 20.7          |\n",
      "|    ep_rew_mean          | -20.7         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 2527          |\n",
      "|    iterations           | 43            |\n",
      "|    time_elapsed         | 510           |\n",
      "|    total_timesteps      | 1290000       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.7844092e-05 |\n",
      "|    clip_fraction        | 0.00117       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.00912      |\n",
      "|    explained_variance   | 0.999         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.0118        |\n",
      "|    n_updates            | 420           |\n",
      "|    policy_gradient_loss | -0.000157     |\n",
      "|    value_loss           | 0.028         |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 203.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating self.num_timesteps=1320000, mean_reward=-20.700000762939453=======\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 20.6       |\n",
      "|    ep_rew_mean          | -20.6      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 2526       |\n",
      "|    iterations           | 44         |\n",
      "|    time_elapsed         | 522        |\n",
      "|    total_timesteps      | 1320000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00823173 |\n",
      "|    clip_fraction        | 0.022      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0366    |\n",
      "|    explained_variance   | 0.999      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.00259   |\n",
      "|    n_updates            | 430        |\n",
      "|    policy_gradient_loss | -0.00115   |\n",
      "|    value_loss           | 0.0274     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 21.9        |\n",
      "|    ep_rew_mean          | -21.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2524        |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 534         |\n",
      "|    total_timesteps      | 1350000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008267655 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.286      |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0253      |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    value_loss           | 0.0288      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 21.4       |\n",
      "|    ep_rew_mean          | -21.4      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 2523       |\n",
      "|    iterations           | 46         |\n",
      "|    time_elapsed         | 546        |\n",
      "|    total_timesteps      | 1380000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06705973 |\n",
      "|    clip_fraction        | 0.0785     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.222     |\n",
      "|    explained_variance   | 0.993      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0069     |\n",
      "|    n_updates            | 450        |\n",
      "|    policy_gradient_loss | -0.0238    |\n",
      "|    value_loss           | 0.135      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 20.6      |\n",
      "|    ep_rew_mean          | -20.6     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 2523      |\n",
      "|    iterations           | 47        |\n",
      "|    time_elapsed         | 558       |\n",
      "|    total_timesteps      | 1410000   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3724729 |\n",
      "|    clip_fraction        | 0.0767    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.052    |\n",
      "|    explained_variance   | 0.997     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.00873  |\n",
      "|    n_updates            | 460       |\n",
      "|    policy_gradient_loss | -0.0469   |\n",
      "|    value_loss           | 0.0843    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 211.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating self.num_timesteps=1440000, mean_reward=-20.399999618530273=======\n",
      "model saved on eval reward: -20.399999618530273\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 20.6          |\n",
      "|    ep_rew_mean          | -20.6         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 2522          |\n",
      "|    iterations           | 48            |\n",
      "|    time_elapsed         | 570           |\n",
      "|    total_timesteps      | 1440000       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00022488831 |\n",
      "|    clip_fraction        | 0.00278       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0505       |\n",
      "|    explained_variance   | 0.997         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.0192        |\n",
      "|    n_updates            | 470           |\n",
      "|    policy_gradient_loss | -0.000162     |\n",
      "|    value_loss           | 0.0289        |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 20.6          |\n",
      "|    ep_rew_mean          | -20.6         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 2521          |\n",
      "|    iterations           | 49            |\n",
      "|    time_elapsed         | 582           |\n",
      "|    total_timesteps      | 1470000       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00041974374 |\n",
      "|    clip_fraction        | 0.00595       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0422       |\n",
      "|    explained_variance   | 0.999         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.0106        |\n",
      "|    n_updates            | 480           |\n",
      "|    policy_gradient_loss | -0.000598     |\n",
      "|    value_loss           | 0.0291        |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 20.6         |\n",
      "|    ep_rew_mean          | -20.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2520         |\n",
      "|    iterations           | 50           |\n",
      "|    time_elapsed         | 595          |\n",
      "|    total_timesteps      | 1500000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012926057 |\n",
      "|    clip_fraction        | 0.00734      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0313      |\n",
      "|    explained_variance   | 0.999        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00998      |\n",
      "|    n_updates            | 490          |\n",
      "|    policy_gradient_loss | -0.000283    |\n",
      "|    value_loss           | 0.0284       |\n",
      "------------------------------------------\n",
      "model saved on eval reward: -20.399999618530273\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x30c75baf0>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner_ckpt_path = 'learner'\n",
    "total_steps = 1500000\n",
    "\n",
    "seed = 937 \n",
    "reseed(seed)\n",
    "\n",
    "# TODO 1: \n",
    "world_vec_env_1 = make_vec_env('WorldModelMountainCar', n_envs=1, env_kwargs={'world_model': world_model})\n",
    "world_vec_env_3 = make_vec_env('WorldModelMountainCar', n_envs=3, env_kwargs={'world_model': world_model})\n",
    "# END TODO\n",
    "\n",
    "learner_callback = PPOCallback(save_path=learner_ckpt_path, eval_env=world_vec_env_1)\n",
    "\n",
    "# TODO 2: \n",
    "learner_model = PPO('MlpPolicy', world_vec_env_3, verbose=1, **hyperparameters)\n",
    "learner_model.learn(total_timesteps=total_steps, callback=learner_callback)\n",
    "\n",
    "# END TODO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hoJ8M-DJPAc6"
   },
   "source": [
    "### 3.2: [PROVIDED] Visualize Policy with Learned World Model and Real Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 456
    },
    "id": "BwVfkzCKPAc6",
    "outputId": "c428fae0-5188-46a7-d208-137640c09afe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/cs4756_a5/lib/python3.10/site-packages/gymnasium/envs/registration.py:788: UserWarning: \u001b[33mWARN: The environment is being initialised with render_mode='rgb_array' that is not in the possible render_modes ([]).\u001b[0m\n",
      "  logger.warn(\n",
      "/opt/anaconda3/envs/cs4756_a5/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:181: DeprecationWarning: \u001b[33mWARN: Current gymnasium version requires that `Env.reset` can be passed `options` to allow the environment initialisation to be passed additional information.\u001b[0m\n",
      "  logger.deprecation(\n",
      "/opt/anaconda3/envs/cs4756_a5/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:135: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method was expecting numpy array dtype to be float32, actual type: float64\u001b[0m\n",
      "  logger.warn(\n",
      "/opt/anaconda3/envs/cs4756_a5/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:159: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n",
      "/opt/anaconda3/envs/cs4756_a5/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:135: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method was expecting numpy array dtype to be float32, actual type: float64\u001b[0m\n",
      "  logger.warn(\n",
      "/opt/anaconda3/envs/cs4756_a5/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:159: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n",
      "/opt/anaconda3/envs/cs4756_a5/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:335: UserWarning: \u001b[33mWARN: No render fps was declared in the environment (env.metadata['render_fps'] is None or not defined), rendering may occur at inconsistent fps.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video saved as learner.mp4\n",
      "Video saved as learner_eval.mp4\n"
     ]
    }
   ],
   "source": [
    "learner_actor = PPOActor(ckpt=f'{learner_ckpt_path}.zip', environment=world_vec_env_1)\n",
    "visualize(\n",
    "    env_name='WorldModelMountainCar',\n",
    "    algorithm=learner_actor,\n",
    "    env_args={\n",
    "        'world_model': world_model\n",
    "    },\n",
    "    video_name=\"learner\",\n",
    ")\n",
    "\n",
    "visualize(\n",
    "    env_name='MountainCar-v0',\n",
    "    algorithm=learner_actor,\n",
    "    video_name=\"learner_eval\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3: Evaluate Learned Policy (2 points) \n",
    "\n",
    "Evaluate the learner agent on both the learned world model and the MountainCar-v0 environment, take note of the numbers, and analyze them in the write up. \n",
    "\n",
    "**Expected Rewards**: \n",
    "- About -160 to -200 on MountainCar-v0\n",
    "- About -30 to -100 on WorldModelMountainCar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 209.27it/s]\n",
      "100%|██████████| 100/100 [00:03<00:00, 26.20it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-200.0"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner_actor = PPOActor(ckpt=f'{learner_ckpt_path}.zip', environment=world_vec_env_1)\n",
    "\n",
    "# TODO: \n",
    "print(\"WorldModelMountainCar:\", evaluate_policy(learner_actor, world_vec_env_1))\n",
    "print(\"MountainCar-v0:\", evaluate_policy(learner_actor, real_vec_env_1))\n",
    "# END TODO: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fGMFxLgiPAc6"
   },
   "source": [
    "## Part 4 (CS 5756 Question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hYlxpuOTPAc6"
   },
   "source": [
    "### 4.1: Collect Data with policy trained on world model (1 point)\n",
    "\n",
    "In this section, we collect another 100000 steps of data with the learned agent from the previous part on the real environment, simulating rollouts of the learned agent in real world. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YCDp5y61PAc7",
    "outputId": "6a62991d-0e27-4db1-a312-0864a84d8c13"
   },
   "outputs": [],
   "source": [
    "real_env = gym.make('MountainCar-v0', render_mode='rgb_array')\n",
    "reseed(data_seed, real_env)\n",
    "\n",
    "# TODO: \n",
    "policy_obs, policy_acts, policy_next_obs = None \n",
    "# END TODO\n",
    "\n",
    "visualize_collected_data(policy_obs, policy_next_obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DsnoInFqPAc7"
   },
   "source": [
    "### 4.2: Aggregate Data (3 point)\n",
    "\n",
    "**Instruction**: Aggregate the expert data collect in Part 2 and the agent data collected from previous section, shuffle their order, and form a new train/val split instances of the `WorldDataset` and dataloaders. \n",
    "- The train / val split should be 80% / 20% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mkVQ7SEhPAc7"
   },
   "outputs": [],
   "source": [
    "# TODO: \n",
    "\n",
    "# END TODO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b2sC203aPAc7"
   },
   "source": [
    "### 4.3: Train a second WorldModel using the new aggregated data (3 points)\n",
    "\n",
    "- Train for 50 epochs with lr=0.0001, Adam optimizer, and MSELoss criterion. \n",
    "- Save the train and validation losses across epochs and plot them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C2LVh_D5PAc7",
    "outputId": "ee08f559-5aca-4a7c-9fcf-d21e2e160a19"
   },
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "reseed(seed)\n",
    "\n",
    "agg_world_model = WorldModel(input_dim=3, hidden_dim_1=16, hidden_dim_2=128, output_dim=2)\n",
    "lr = 0.0001\n",
    "agg_optimizer = torch.optim.Adam(agg_world_model.parameters(), lr=lr)\n",
    "agg_criterion = nn.MSELoss()\n",
    "\n",
    "\n",
    "# TODO: \n",
    "\n",
    "# END TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the resulting model through expert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_-ASfx8DPAc7",
    "outputId": "cc53330d-a56f-4e9d-cfc9-b888f33fa27e"
   },
   "outputs": [],
   "source": [
    "# visualize on trained expert\n",
    "visualize(\n",
    "    env_name='WorldModelMountainCar',\n",
    "    algorithm=expert,\n",
    "    video_name='expert_agg_trained_world',\n",
    "    env_args={\n",
    "        'world_model': agg_world_model\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4: Train new PPO policy on world model from 4.3 (4 points)\n",
    "\n",
    "**TODO 1 Instruction**: Initialize a 3-vectorized and a 1-vectorized WorldModelMountainCar environment with the world model trained on aggregated dataset\n",
    "\n",
    "**TODO 2 Instruction**: Train a separate PPO policy using the world model learned on aggregated data. Similar as before, this model should be trained for 1500000 steps, under a 3-vectorized environment, using the same hyperparameters provided in Part 1. \n",
    "\n",
    "**Note**: Here is a list of created environments after running this following cell: \n",
    "- `real_vec_env_1` \n",
    "- `real_vec_env_3` \n",
    "- `real_env` \n",
    "- `world_vec_env_1` \n",
    "- `world_vec_env_3`\n",
    "- `agg_world_vec_env_1` \n",
    "- `agg_world_vec_env_3`\n",
    "\n",
    "Refer to function documentation for selecting which one to use when doing function calls. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_ckpt_path = 'agg_learner'\n",
    "total_steps = 1500000\n",
    "\n",
    "reseed(seed) \n",
    "\n",
    "# TODO 1: \n",
    "agg_world_vec_env_3 = None\n",
    "agg_world_vec_env_1 = None\n",
    "# END TODO \n",
    "\n",
    "policy_callback = PPOCallback(save_path=agg_ckpt_path, eval_env=agg_world_vec_env_1)\n",
    "\n",
    "# TODO : \n",
    "\n",
    "# END TODO\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the aggregated PPO Agent on both real environment and learned world environment (2 points)  \n",
    "\n",
    "**Expected Rewards** \n",
    "- About -120 to -150 on MountainCar-v0 \n",
    "- About -100 to -140 on learned environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_learner_actor = PPOActor(ckpt='agg_learner.zip', environment=agg_world_vec_env_3)\n",
    "\n",
    "# TODO: \n",
    "\n",
    "# END TODO"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "OyawBbGNPAc6"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "cs4756_a5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
